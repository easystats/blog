<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on easystats</title>
    <link>/blog/categories/r/</link>
    <description>Recent content in R on easystats</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 12 May 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/blog/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>In defence of the 95% CI</title>
      <link>/blog/posts/bayestestr_95/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_95/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;&lt;strong&gt;BayestestR&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;currently uses a 89% threshold by default for Credible Intervals (CI). Should we change that? If so, by what?&lt;/strong&gt; &lt;a href=&#34;https://github.com/easystats/bayestestR/issues/250&#34;&gt;&lt;strong&gt;&lt;em&gt;Join the discussion here.&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Magical numbers, or conventional thresholds, have bad press in statistics, and there are many of them. For instance, &lt;strong&gt;.05&lt;/strong&gt; (for the &lt;em&gt;p&lt;/em&gt;-value), or the &lt;strong&gt;95%&lt;/strong&gt; range for the &lt;strong&gt;Confidence Interval&lt;/strong&gt; (CI). Indeed, why 95 and not 94 or 90?&lt;/p&gt;
&lt;p&gt;One of the issue that traditional confidence intervals are often being interpreted as a description of the uncertainty surrounding a parameter’s value. Almost as if the estimation resulted in a &lt;strong&gt;probability distribution&lt;/strong&gt;, from which the confidence interval is describing the &lt;em&gt;width&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Well the traditional confidence interval is &lt;strong&gt;not that&lt;/strong&gt;, and this probabilistic interpretation pertains in fact to the &lt;strong&gt;&lt;em&gt;Credible&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;Interval&lt;/strong&gt; obtained via Bayesian methods. Indeed, in the Bayesian framework, parameters of a model are given as probability distributions that we need to describe (see this &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayestestR.html&#34;&gt;gentle introduction to Bayes&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;And as you might know, &lt;em&gt;some&lt;/em&gt; Bayesianists tend to think that their philosophy is superior to that of the frequentist empire (&lt;em&gt;could be true though&lt;/em&gt;). Also, as the Bayesian field is growing, people see it as a new world and a promissing opportunity to make things right, and correct the mistakes that have been poisoning the old world.&lt;/p&gt;
&lt;p&gt;This has led experts to question the validity of this 95% range, which appeared as arbitrary, and closely related to the &lt;em&gt;p&lt;/em&gt;-value and the notion of &lt;strong&gt;significance&lt;/strong&gt; (&lt;em&gt;ewww&lt;/em&gt;). This, as well as because of some computational reasons (related to the stability of the bounds of a distribution in relationship with the number of samples), has led some to move away from 95%, and use for instance 90%. Recently, the great McElreath, in his awesome book &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;&lt;strong&gt;Statistical Rethinking&lt;/strong&gt;&lt;/a&gt;, made the case for using 89%, to underline the arbitrary nature of such threshold.&lt;/p&gt;
&lt;p&gt;However, there might be a few arguments that could potentially be made &lt;strong&gt;in favour&lt;/strong&gt; of this “magical value”.&lt;/p&gt;
&lt;div id=&#34;reproducibility-and-continuation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reproducibility and continuation&lt;/h2&gt;
&lt;p&gt;The scientific landscape, especially in social and neuro- sciences, has been recently shaken by the so-called &lt;strong&gt;reproducibility crisis&lt;/strong&gt;. People realized that the science they trusted was akin to a collossus with clay feet: many “facts” and published results were not replicable, and most of them were not &lt;strong&gt;reproducible&lt;/strong&gt;. The full steps to go from data to results were either not provided, or not described with enough details to allow other researchers to apply the exact same pipeline, with the end goal of &lt;em&gt;comparing&lt;/em&gt; the results.&lt;/p&gt;
&lt;p&gt;Indeed, most scientific results, or result numbers, are relative, in the sense that they are to be interpreted in the context of a method, measure, field or context. &lt;strong&gt;People sometimes joke that a correlation of .70 is a disaster in physics but a miracle in psychology&lt;/strong&gt;. As such, it is important that we take this continuity of science into account when making decisions. Let’s say everybody, from Newton and Copernicus, used &lt;code&gt;Pi = 3.10&lt;/code&gt;. Should we change that? Sure, because it’s a &lt;em&gt;bad&lt;/em&gt; number and a bad approximation, and using &lt;code&gt;Pi = 3.14&lt;/code&gt; is &lt;em&gt;objectively&lt;/em&gt; better. But in the case where there is no strong reason to do so, should we change conventions, just for the sake of change?&lt;/p&gt;
&lt;p&gt;By switching to reporting 89% intervals, mainly for the sake of heightening the wall between the Bayesian and the frequentist worlds, it seems like it kind of goes against this idea of continuity and additivity of scientific results. And I’m not sure the benefits outweight the drawbacks.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;purpose-of-such-interval&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Purpose of such &lt;em&gt;interval&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;People often use the credible interval to describe the &lt;strong&gt;uncertainty&lt;/strong&gt; related to their parameters, because &lt;strong&gt;uncertainty&lt;/strong&gt; is key and should be embraced. But you might ask, why not use another index of uncertainty, - and dispersion, such as for instance the standard deviation &lt;strong&gt;SD&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;Well, some people describe both, but in that case you might also add the MAD, and all ranges of the credible interval. In fact, you might as well return the whole density plot (though if you can, it’s the best thing to do. And do check out the great &lt;a href=&#34;https://github.com/mjskay/tidybayes/&#34;&gt;&lt;strong&gt;tidybayes package&lt;/strong&gt; for awesome visualization tools&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;So, what are the advantages of the CI over the SD? Well, one difference is that the CI bounds are often seen as an approximation of the limits of a distribution (or its plausible region). What does it mean? Take this example. Let’s imagine this distribution of mean 0 and SD 1 made of a lot of points:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bayestestR)
library(see)

x &amp;lt;- distribution_normal(10^6, mean = 0, sd = 1)

plot(estimate_density(x)) +
  theme_modern()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_95_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While this empirical distribution of values has real bounds (it has a minimum and a maximum value), these are merely a computational “artifact”. In theory, this distribution covers the whole range of real values, extending until infinity (and beyond). All values are &lt;em&gt;possible&lt;/em&gt;, albeit very very very very &lt;strong&gt;unlikely&lt;/strong&gt;. But despite this mathematical fact, our chunking-loving brain understands that the important stuff is happening somewhere between -3 and 3.&lt;/p&gt;
&lt;p&gt;As such, the uncertainty interval can be used to convey a rough (and artificial) sense of the limits of the likely area. Having edges of plausibility is arguably more intuitive than a single dispersion index, such as SD, facilitating decision making (for instance, if this range covers 0) and interpretations.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;relationship-with-the-sd&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Relationship with the SD&lt;/h2&gt;
&lt;p&gt;Alright, we see how returning a credible interval is useful and provides intuitive information about the “limits” of a continuous distribution. On the other hand, the SD is such a mathematical marvel, tied with other useful concepts such as &lt;em&gt;z&lt;/em&gt;-scores, standardization etc. It is indeed tempting to return both the CI and the SD. But as we said, reporting too much information can also hinder the readibility of a document, so which one to pick (if we had to)?&lt;/p&gt;
&lt;p&gt;Moreover, the SD can also be used to describe the width of a distribution. For instance, we know that the bulk of a normal distribution lies within 6 SD around the mean. In the case above, the majority of points fall within -3 SD to 3 SD. When I say the bulk, it’s about 99.7% of the values, which arguably includes also quite improbable values.&lt;/p&gt;
&lt;p&gt;So what if we restricted the range a bit, and took the range from -2 SD to 2 SD? Interestingly, such range includes, &lt;em&gt;you guessed it&lt;/em&gt;, about 95% of the values (95.45).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

plot(ci(x, ci=0.95)) +
  scale_x_continuous(breaks = -3:3) +
  theme_modern()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_95_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That means that we can roughly approximate the 95% range from the SD… and &lt;em&gt;vice versa&lt;/em&gt;. If a 95% range is [2, 10], it means that the SD is probably somewhere around &lt;code&gt;(10 - 2) / 4 = 2&lt;/code&gt;. And this means that there is a rough correspondance between the 95% CI and the SD, connecting these two concepts in a more general and intuitive understanding of a distribution&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I see you comming&lt;/strong&gt;. &lt;em&gt;“But this approximation is only true for normal distributions and posterior distributions are not (or should not be) always normal”&lt;/em&gt;. &lt;em&gt;“This is misguided and will create more confusion in the minds of the padawan”&lt;/em&gt;. It’s true that this relationship is not an absolute mathematical truth, but merely a heuristic that could foster the embrace of a deeper understanding of uncertainty. Could it be misleading? I’m not sure.&lt;/p&gt;
&lt;p&gt;All in all, these are some elements that could be made to support the usage of the 95% range. They might not be the strongest arguments, which opens up a debate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-do-you-think&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What do you think?&lt;/h2&gt;
&lt;p&gt;In our package &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;&lt;strong&gt;bayestestR&lt;/strong&gt;&lt;/a&gt;, we previously used &lt;code&gt;0.89&lt;/code&gt; by default, that returned the 89% CI. But as we like to challenge ourselves, we are looking for arguments in favour, or against, its change.&lt;/p&gt;
&lt;p&gt;Thus, we’d like to invite you to give your opinion or vote on the &lt;a href=&#34;https://github.com/easystats/bayestestR/issues/250&#34;&gt;dedicated issue&lt;/a&gt;. Thanks :)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note: this is an opinion article written by me and that it does not necessarily reflect the opinions of the other easystats members, nor the opinion of my family, my people and that of the Human species.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;easystats&lt;/em&gt; is a new project in active development, looking for contributors and supporters. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;stay-tuned&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stay tuned&lt;/h2&gt;
&lt;p&gt;To be updated about the &lt;em&gt;upcoming features&lt;/em&gt; and cool R or data science stuff, you can &lt;strong&gt;follow the packages on GitHub&lt;/strong&gt; (click on one &lt;a href=&#34;https://github.com/easystats&#34;&gt;of the easystats package&lt;/a&gt;) and then on the &lt;strong&gt;Watch&lt;/strong&gt; button on the top right corner) as well as the &lt;strong&gt;easystats team on twitter and online&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/easystats4u&#34;&gt;@easystats4u&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/strengejacke&#34;&gt;@strengejacke&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34;&gt;@DominiqueMakowski&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/mattansb&#34;&gt;@mattansb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/patilindrajeets&#34;&gt;@IndrajeetPatil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/humanfactorsio&#34;&gt;@humanfactors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jonaslindeloev&#34;&gt;@lindeloev&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jacobandrewlong&#34;&gt;@jacob-long&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pdwaggoner.github.io/&#34;&gt;@pdwaggoner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/LDtrx&#34;&gt;@LeoDutriaux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>bayestestR</category>
      
      
            <category>R</category>
      
            <category>bayestestR</category>
      
    </item>
    
    <item>
      <title>Multilevel Correlations: A New Method for Common Problems</title>
      <link>/blog/posts/correlation_multilevel/</link>
      <pubDate>Tue, 14 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/correlation_multilevel/</guid>
      <description>


&lt;p&gt;In this tutorial, we will introduce &lt;strong&gt;multilevel correlations&lt;/strong&gt; (or &lt;em&gt;hierarchical&lt;/em&gt; / &lt;em&gt;random-effects&lt;/em&gt; correlations) and how to compute them using the new &lt;a href=&#34;https://github.com/easystats/correlation&#34;&gt;&lt;strong&gt;correlations&lt;/strong&gt;&lt;/a&gt; package from the &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats suite&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can install the updated version and load the package as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;correlation&amp;quot;)
library(correlation)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;Imagine we have an experiment in which &lt;strong&gt;10 individuals&lt;/strong&gt; completed a task with &lt;strong&gt;100 trials&lt;/strong&gt;. For each of the 1000 total trials, we measured two things, &lt;strong&gt;V1&lt;/strong&gt; and &lt;strong&gt;V2&lt;/strong&gt;, and our research aims at &lt;strong&gt;investingating the link between these two variables&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We will generate data using the &lt;a href=&#34;https://easystats.github.io/correlation/reference/simulate_simpson.html&#34;&gt;&lt;code&gt;simulate_simpson()&lt;/code&gt;&lt;/a&gt; function from the &lt;code&gt;correlation&lt;/code&gt; package installed above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- simulate_simpson(n=100, groups=10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s visualize the two variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

ggplot(data, aes(x=V1, y=V2)) + 
  geom_point() +
  geom_smooth(colour=&amp;quot;black&amp;quot;, method=&amp;quot;lm&amp;quot;, se=FALSE) +
  theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/correlation_multilevel_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That seems pretty straightfoward! It seems like there is a &lt;strong&gt;negative correlation&lt;/strong&gt; between V1 and V2. Let’s test this.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-correlation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simple correlation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;correlation(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter1 | Parameter2 |     r |         95% CI |      t |  df |      p |  Method | n_Obs
## ------------------------------------------------------------------------------------------
## V1         |         V2 | -0.84 | [-0.86, -0.82] | -48.77 | 998 | &amp;lt; .001 | Pearson |  1000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, there is &lt;strong&gt;strong, negative and significant correlation&lt;/strong&gt; between V1 and V2. Great, can we go ahead and &lt;strong&gt;publish these results in PNAS&lt;/strong&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-simpsons-paradox&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Simpson’s Paradox&lt;/h2&gt;
&lt;p&gt;Hold on sunshine! Ever heard of something called the &lt;a href=&#34;https://en.wikipedia.org/wiki/Simpson%27s_paradox&#34;&gt;&lt;strong&gt;Simpson’s Paradox&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;Let’s colour our datapoints by group (by individuals):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

ggplot(data, aes(x=V1, y=V2)) + 
  geom_point(aes(colour=Group)) +
  geom_smooth(aes(colour=Group), method=&amp;quot;lm&amp;quot;, se=FALSE) + 
  geom_smooth(colour=&amp;quot;black&amp;quot;, method=&amp;quot;lm&amp;quot;, se=FALSE) + 
  theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/correlation_multilevel_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Mmh&lt;/em&gt;, interesting. It seems like, for each subject, the relationship is different. The negative general trend seems to be created by &lt;strong&gt;differences between the groups&lt;/strong&gt; and could be spurious!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multilevel &lt;em&gt;(as in multi-group)&lt;/em&gt; correlations allow us to account for differences between groups&lt;/strong&gt;. It is based on a partialization of the group variable, entered as a random factor in a mixed linear regression.&lt;/p&gt;
&lt;p&gt;You can compute them with the &lt;a href=&#34;https://github.com/easystats/correlation&#34;&gt;&lt;strong&gt;correlations&lt;/strong&gt;&lt;/a&gt; package by setting the &lt;code&gt;multilevel&lt;/code&gt; arguent to &lt;code&gt;TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;correlation(data, multilevel = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter1 | Parameter2 |    r |           CI |     t |  df |      p |  Method | n_Obs
## --------------------------------------------------------------------------------------
## V1         |         V2 | 0.50 | [0.45, 0.55] | 18.23 | 998 | &amp;lt; .001 | Pearson |  1000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Dayum!&lt;/strong&gt; We were too hasty in our conclusions! Taking the group into account seems to be super important.&lt;/p&gt;
&lt;p&gt;Note: In this simple case where only two variables are of interest, it would be of course best to directly proceed using a mixed regression model instead of correlations. That being said, the latter can be useful for exploratory analysis, when multiple variables are of interest, or in combination with a network or structural approach.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;easystats&lt;/em&gt; is a new project in active development, looking for contributors and supporters. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;stay-tuned&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stay tuned&lt;/h2&gt;
&lt;p&gt;To be updated about the &lt;em&gt;upcoming features&lt;/em&gt; and cool R or data science stuff, you can &lt;strong&gt;follow the packages on GitHub&lt;/strong&gt; (click on one &lt;a href=&#34;https://github.com/easystats&#34;&gt;of the easystats package&lt;/a&gt;) and then on the &lt;strong&gt;Watch&lt;/strong&gt; button on the top right corner) as well as the &lt;strong&gt;easystats team on twitter and online&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/easystats4u&#34;&gt;@easystats4u&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/strengejacke&#34;&gt;@strengejacke&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34;&gt;@DominiqueMakowski&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/mattansb&#34;&gt;@mattansb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/patilindrajeets&#34;&gt;@IndrajeetPatil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/humanfactorsio&#34;&gt;@humanfactors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jonaslindeloev&#34;&gt;@lindeloev&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jacobandrewlong&#34;&gt;@jacob-long&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pdwaggoner.github.io/&#34;&gt;@pdwaggoner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/LDtrx&#34;&gt;@LeoDutriaux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>correlation</category>
      
      
            <category>R</category>
      
            <category>correlation</category>
      
    </item>
    
    <item>
      <title>The ulimate package for correlations (by easystats)</title>
      <link>/blog/posts/correlation_presentation/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/correlation_presentation/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/correlation/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;the-correlation-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The correlation package&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats project&lt;/strong&gt;&lt;/a&gt; continues to grow with its more recent addition, a package devoted to &lt;strong&gt;correlations&lt;/strong&gt;. Check-out its &lt;a href=&#34;https://github.com/easystats/correlation&#34;&gt;&lt;strong&gt;webpage here&lt;/strong&gt;&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;It’s lightweight, easy to use, and allows for the computation of many different kinds of correlations, such as &lt;strong&gt;partial&lt;/strong&gt; correlations, &lt;strong&gt;Bayesian&lt;/strong&gt; correlations, &lt;strong&gt;multilevel&lt;/strong&gt; correlations, &lt;strong&gt;polychoric&lt;/strong&gt; correlations, &lt;strong&gt;biweight&lt;/strong&gt;, &lt;strong&gt;percentage bend&lt;/strong&gt; or &lt;strong&gt;Sheperd’s Pi&lt;/strong&gt; correlations (types of &lt;strong&gt;robust&lt;/strong&gt; correlation), &lt;strong&gt;distance&lt;/strong&gt; correlation (a type of &lt;strong&gt;non-linear&lt;/strong&gt; correlation) and more, also allowing for combinations between them (for instance, &lt;em&gt;Bayesian partial multilevel correlation&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;You can install and load the package as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;correlation&amp;quot;)
library(correlation)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;The main function is &lt;a href=&#34;https://easystats.github.io/correlation/reference/correlation.html&#34;&gt;&lt;code&gt;correlation()&lt;/code&gt;&lt;/a&gt;, which builds on top of &lt;a href=&#34;https://easystats.github.io/correlation/reference/cor_test.html&#34;&gt;&lt;code&gt;cor_test()&lt;/code&gt;&lt;/a&gt; and comes with a number of possible options.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-details-and-matrix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Correlation details and matrix&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor &amp;lt;- correlation(iris)
cor&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter1   |   Parameter2 |     r |         95% CI |     t |  df |      p |  Method | n_Obs
## ---------------------------------------------------------------------------------------------
## Sepal.Length |  Sepal.Width | -0.12 | [-0.27,  0.04] | -1.44 | 148 | 0.152  | Pearson |   150
## Sepal.Length | Petal.Length |  0.87 | [ 0.83,  0.91] | 21.65 | 148 | &amp;lt; .001 | Pearson |   150
## Sepal.Length |  Petal.Width |  0.82 | [ 0.76,  0.86] | 17.30 | 148 | &amp;lt; .001 | Pearson |   150
## Sepal.Width  | Petal.Length | -0.43 | [-0.55, -0.29] | -5.77 | 148 | &amp;lt; .001 | Pearson |   150
## Sepal.Width  |  Petal.Width | -0.37 | [-0.50, -0.22] | -4.79 | 148 | &amp;lt; .001 | Pearson |   150
## Petal.Length |  Petal.Width |  0.96 | [ 0.95,  0.97] | 43.39 | 148 | &amp;lt; .001 | Pearson |   150&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output is not a square matrix, but a &lt;strong&gt;(tidy) dataframe with all correlations tests per row&lt;/strong&gt;. One can also obtain a &lt;strong&gt;matrix&lt;/strong&gt; using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(cor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter    | Petal.Width | Petal.Length | Sepal.Width
## -------------------------------------------------------
## Sepal.Length |     0.82*** |      0.87*** |       -0.12
## Sepal.Width  |    -0.37*** |     -0.43*** |            
## Petal.Length |     0.96*** |              |&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that one can also obtain the full, &lt;strong&gt;square&lt;/strong&gt; and redundant matrix using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.table(cor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter    | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width
## ----------------------------------------------------------------------
## Sepal.Length |      1.00*** |       -0.12 |      0.87*** |     0.82***
## Sepal.Width  |        -0.12 |     1.00*** |     -0.43*** |    -0.37***
## Petal.Length |      0.87*** |    -0.43*** |      1.00*** |     0.96***
## Petal.Width  |      0.82*** |    -0.37*** |      0.96*** |     1.00***&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;grouped-dataframes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Grouped dataframes&lt;/h2&gt;
&lt;p&gt;The function also supports &lt;strong&gt;stratified correlations&lt;/strong&gt;, all within the &lt;em&gt;tidyverse&lt;/em&gt; workflow!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

iris %&amp;gt;% 
  select(Species, Petal.Width, Sepal.Length, Sepal.Width) %&amp;gt;%
  group_by(Species) %&amp;gt;% 
  correlation()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Group      |   Parameter1 |   Parameter2 |    r |        95% CI |    t | df |      p |  Method | n_Obs
## ------------------------------------------------------------------------------------------------------
## setosa     |  Petal.Width | Sepal.Length | 0.28 | [ 0.00, 0.52] | 2.01 | 48 | 0.101  | Pearson |    50
## setosa     |  Petal.Width |  Sepal.Width | 0.23 | [-0.05, 0.48] | 1.66 | 48 | 0.104  | Pearson |    50
## setosa     | Sepal.Length |  Sepal.Width | 0.74 | [ 0.59, 0.85] | 7.68 | 48 | &amp;lt; .001 | Pearson |    50
## versicolor |  Petal.Width | Sepal.Length | 0.55 | [ 0.32, 0.72] | 4.52 | 48 | &amp;lt; .001 | Pearson |    50
## versicolor |  Petal.Width |  Sepal.Width | 0.66 | [ 0.47, 0.80] | 6.15 | 48 | &amp;lt; .001 | Pearson |    50
## versicolor | Sepal.Length |  Sepal.Width | 0.53 | [ 0.29, 0.70] | 4.28 | 48 | &amp;lt; .001 | Pearson |    50
## virginica  |  Petal.Width | Sepal.Length | 0.28 | [ 0.00, 0.52] | 2.03 | 48 | 0.048  | Pearson |    50
## virginica  |  Petal.Width |  Sepal.Width | 0.54 | [ 0.31, 0.71] | 4.42 | 48 | &amp;lt; .001 | Pearson |    50
## virginica  | Sepal.Length |  Sepal.Width | 0.46 | [ 0.20, 0.65] | 3.56 | 48 | 0.002  | Pearson |    50&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-correlations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian Correlations&lt;/h2&gt;
&lt;p&gt;It is very easy to switch to a &lt;strong&gt;Bayesian framework&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;correlation(iris, bayesian=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter1   |   Parameter2 |   rho |         95% CI |     pd | % in ROPE |    BF |              Prior | n_Obs
## --------------------------------------------------------------------------------------------------------------
## Sepal.Length |  Sepal.Width | -0.11 | [-0.23,  0.02] | 92.22% |    42.75% |  0.51 | Cauchy (0 +- 0.33) |   150
## Sepal.Length | Petal.Length |  0.86 | [ 0.83,  0.89] |   100% |        0% | &amp;gt; 999 | Cauchy (0 +- 0.33) |   150
## Sepal.Length |  Petal.Width |  0.81 | [ 0.76,  0.85] |   100% |        0% | &amp;gt; 999 | Cauchy (0 +- 0.33) |   150
## Sepal.Width  | Petal.Length | -0.41 | [-0.52, -0.31] |   100% |        0% | &amp;gt; 999 | Cauchy (0 +- 0.33) |   150
## Sepal.Width  |  Petal.Width | -0.36 | [-0.46, -0.24] |   100% |        0% | &amp;gt; 999 | Cauchy (0 +- 0.33) |   150
## Petal.Length |  Petal.Width |  0.96 | [ 0.95,  0.97] |   100% |        0% | &amp;gt; 999 | Cauchy (0 +- 0.33) |   150&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tetrachoric-polychoric-biserial-biweight&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tetrachoric, Polychoric, Biserial, Biweight…&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;correlation&lt;/code&gt; package also supports different types of methods, which can deal with correlations &lt;strong&gt;between factors&lt;/strong&gt;!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;correlation(iris, include_factors = TRUE, method = &amp;quot;auto&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter1         |         Parameter2 |     r |         95% CI |      t |  df |      p |         Method | n_Obs
## -----------------------------------------------------------------------------------------------------------------
## Sepal.Length       |        Sepal.Width | -0.12 | [-0.27,  0.04] |  -1.44 | 148 | 0.452  |        Pearson |   150
## Sepal.Length       |       Petal.Length |  0.87 | [ 0.83,  0.91] |  21.65 | 148 | &amp;lt; .001 |        Pearson |   150
## Sepal.Length       |        Petal.Width |  0.82 | [ 0.76,  0.86] |  17.30 | 148 | &amp;lt; .001 |        Pearson |   150
## Sepal.Length       |     Species.setosa | -0.72 | [-0.79, -0.63] | -12.53 | 148 | &amp;lt; .001 | Point-biserial |   150
## Sepal.Length       | Species.versicolor |  0.08 | [-0.08,  0.24] |   0.97 | 148 | 0.452  | Point-biserial |   150
## Sepal.Length       |  Species.virginica |  0.64 | [ 0.53,  0.72] |  10.08 | 148 | &amp;lt; .001 | Point-biserial |   150
## Sepal.Width        |       Petal.Length | -0.43 | [-0.55, -0.29] |  -5.77 | 148 | &amp;lt; .001 |        Pearson |   150
## Sepal.Width        |        Petal.Width | -0.37 | [-0.50, -0.22] |  -4.79 | 148 | &amp;lt; .001 |        Pearson |   150
## Sepal.Width        |     Species.setosa |  0.60 | [ 0.49,  0.70] |   9.20 | 148 | &amp;lt; .001 | Point-biserial |   150
## Sepal.Width        | Species.versicolor | -0.47 | [-0.58, -0.33] |  -6.44 | 148 | &amp;lt; .001 | Point-biserial |   150
## Sepal.Width        |  Species.virginica | -0.14 | [-0.29,  0.03] |  -1.67 | 148 | 0.392  | Point-biserial |   150
## Petal.Length       |        Petal.Width |  0.96 | [ 0.95,  0.97] |  43.39 | 148 | &amp;lt; .001 |        Pearson |   150
## Petal.Length       |     Species.setosa | -0.92 | [-0.94, -0.89] | -29.13 | 148 | &amp;lt; .001 | Point-biserial |   150
## Petal.Length       | Species.versicolor |  0.20 | [ 0.04,  0.35] |   2.51 | 148 | 0.066  | Point-biserial |   150
## Petal.Length       |  Species.virginica |  0.72 | [ 0.63,  0.79] |  12.66 | 148 | &amp;lt; .001 | Point-biserial |   150
## Petal.Width        |     Species.setosa | -0.89 | [-0.92, -0.85] | -23.41 | 148 | &amp;lt; .001 | Point-biserial |   150
## Petal.Width        | Species.versicolor |  0.12 | [-0.04,  0.27] |   1.44 | 148 | 0.452  | Point-biserial |   150
## Petal.Width        |  Species.virginica |  0.77 | [ 0.69,  0.83] |  14.66 | 148 | &amp;lt; .001 | Point-biserial |   150
## Species.setosa     | Species.versicolor | -0.88 | [-0.91, -0.84] | -22.35 | 148 | &amp;lt; .001 |    Tetrachoric |   150
## Species.setosa     |  Species.virginica | -0.88 | [-0.91, -0.84] | -22.35 | 148 | &amp;lt; .001 |    Tetrachoric |   150
## Species.versicolor |  Species.virginica | -0.88 | [-0.91, -0.84] | -22.35 | 148 | &amp;lt; .001 |    Tetrachoric |   150&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;partial-correlations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Partial Correlations&lt;/h2&gt;
&lt;p&gt;It also supports &lt;strong&gt;partial correlations&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% 
  correlation(partial = TRUE) %&amp;gt;% 
  summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter    | Petal.Width | Petal.Length | Sepal.Width
## -------------------------------------------------------
## Sepal.Length |    -0.34*** |      0.72*** |     0.63***
## Sepal.Width  |     0.35*** |     -0.62*** |            
## Petal.Length |     0.87*** |              |&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;gaussian-graphical-models-ggms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gaussian Graphical Models (GGMs)&lt;/h2&gt;
&lt;p&gt;Such partial correlations can also be represented as &lt;strong&gt;Gaussian graphical models&lt;/strong&gt;, an increasingly popular tool in psychology:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(see) # for plotting
library(ggraph) # needs to be loaded

mtcars %&amp;gt;% 
  correlation(partial = TRUE) %&amp;gt;% 
  plot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/correlation_presentation_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;easystats&lt;/em&gt; is a new project in active development, looking for contributors and supporters. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;stay-tuned&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stay tuned&lt;/h2&gt;
&lt;p&gt;To be updated about the &lt;em&gt;upcoming features&lt;/em&gt; and cool R or data science stuff, you can &lt;strong&gt;follow the packages on GitHub&lt;/strong&gt; (click on one &lt;a href=&#34;https://github.com/easystats&#34;&gt;of the easystats package&lt;/a&gt;) and then on the &lt;strong&gt;Watch&lt;/strong&gt; button on the top right corner) as well as the &lt;strong&gt;easystats team on twitter and online&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/easystats4u&#34;&gt;@easystats4u&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/strengejacke&#34;&gt;@strengejacke&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34;&gt;@DominiqueMakowski&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/mattansb&#34;&gt;@mattansb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/patilindrajeets&#34;&gt;@IndrajeetPatil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/humanfactorsio&#34;&gt;@humanfactors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jonaslindeloev&#34;&gt;@lindeloev&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jacobandrewlong&#34;&gt;@jacob-long&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pdwaggoner.github.io/&#34;&gt;@pdwaggoner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/LDtrx&#34;&gt;@LeoDutriaux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>correlation</category>
      
      
            <category>R</category>
      
            <category>correlation</category>
      
    </item>
    
    <item>
      <title>The p-direction: A Bayesian equivalent of the p-value?</title>
      <link>/blog/posts/bayestestr_pd/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_pd/</guid>
      <description>


&lt;p&gt;The Bayesian framework is powerful and allows for an incredible amount of flexibility and control over your analysis. That being said, newcomers often struggle with a lot of new concepts and tools and could benefit from some &lt;strong&gt;familiar grounding&lt;/strong&gt;. And the &lt;em&gt;p&lt;/em&gt;-value is a very familiar index (although paradoxically often misunderstood, but that’s another topic).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Is there an equivalent of the &lt;em&gt;p&lt;/em&gt;-value?&lt;/strong&gt; Well, depends on what “equivalent” means. Some might argue that the &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayes_factors.html&#34;&gt;&lt;strong&gt;Bayes factor&lt;/strong&gt;&lt;/a&gt; is some sort of equivalent, i.e., a value that can be used for decisions and interpretation of results. &lt;a href=&#34;https://www.youtube.com/watch?v=Ip8Ci5KUVRc&amp;amp;t=408s&#34;&gt;Some others&lt;/a&gt; would suggest that the &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/p_map.html&#34;&gt;MAP-based &lt;em&gt;p&lt;/em&gt;-value&lt;/a&gt; is another alternative.&lt;/p&gt;
&lt;p&gt;Based on a simulation study &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02767/full&#34;&gt;(Makowski et al., 2019)&lt;/a&gt;, we think that the &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/probability_of_direction.html&#34;&gt;&lt;strong&gt;probability of direction&lt;/strong&gt;&lt;/a&gt; (&lt;em&gt;p&lt;/em&gt;-direction, or &lt;em&gt;pd&lt;/em&gt;) is the closest &lt;strong&gt;&lt;em&gt;statistical&lt;/em&gt; equivalent to the &lt;em&gt;p&lt;/em&gt;-value&lt;/strong&gt;. The &lt;em&gt;statistical&lt;/em&gt; is important here, simply meaning that the two indices are strongly correlated. That being said, they are &lt;strong&gt;not &lt;em&gt;conceptually&lt;/em&gt; equivalent&lt;/strong&gt; (as we argue in the paper, the &lt;em&gt;pd&lt;/em&gt; is an index of effect &lt;em&gt;existence&lt;/em&gt;, rather than &lt;em&gt;significance&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Here’s a short example.&lt;/p&gt;
&lt;div id=&#34;frequentist-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist regression&lt;/h2&gt;
&lt;p&gt;First, you can install (or update) the necessary packages by running the following (it’s important that the &lt;em&gt;insight&lt;/em&gt; package version must be &amp;gt;= 0.8.1):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(c(&amp;quot;insight&amp;quot;, &amp;quot;bayestestR&amp;quot;, &amp;quot;parameters&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s start by running a simple linear regression and displaying its result with the &lt;a href=&#34;https://easystats.github.io/parameters/&#34;&gt;&lt;strong&gt;parameters&lt;/strong&gt;&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(parameters)

model &amp;lt;- lm(disp ~ carb, data = mtcars)
parameters(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter   | Coefficient |    SE |          95% CI |    t | df |     p
## -----------------------------------------------------------------------
## (Intercept) |      145.48 | 41.58 | [60.56, 230.40] | 3.50 | 30 | 0.001
## carb        |       30.31 | 12.87 | [ 4.02,  56.59] | 2.35 | 30 | 0.025&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value of the linear relationship between the two variable is of &lt;em&gt;.025&lt;/em&gt; (the second row in the &lt;em&gt;p&lt;/em&gt; column). What does a Bayesian analysis tells us?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-regression-with-flat-priors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian regression (with flat priors)&lt;/h2&gt;
&lt;p&gt;As you might know, a Bayesian analysis is close to a maximum likelihood analysis (the typical frequentist paradigm) when no information is given by the prior (and the result is only driven by the data). This is the case with &lt;strong&gt;flat priors&lt;/strong&gt;, that give equivalent likelihood to each and every one of your wildest dreams (see the &lt;a href=&#34;https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html&#34;&gt;&lt;em&gt;How to Specify Flat Priors (and why you typically shouldn’t)&lt;/em&gt;&lt;/a&gt; section).&lt;/p&gt;
&lt;p&gt;Let’s fit the same regression as above within a Bayesian framework with a flat prior (i.e., by setting them as &lt;code&gt;NULL&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bayestestR)
library(rstanarm)

model &amp;lt;-
  stan_glm(
    disp ~ carb,
    data = mtcars,
    priors = NULL,
    prior_intercept = NULL
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter   | Median |          89% CI |     pd | % in ROPE |  Rhat |   ESS |                Prior
## --------------------------------------------------------------------------------------------------
## (Intercept) | 145.97 | [78.68, 212.98] | 99.92% |     0.11% | 1.000 | 55624 |       Uniform ( +- )
## carb        |  30.24 | [ 9.47,  51.26] | 98.80% |     8.50% | 1.000 | 52688 | Normal (0 +- 191.83)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It tells us that the &lt;em&gt;p&lt;/em&gt;-direction is of 98.80%, i.e., &lt;code&gt;0.9880&lt;/code&gt; (note that your results can slightly vary due to the random nature of the sampling; you can increase the number of iterations to get more stable results). We can quickly visualize its meaning as follows (with the &lt;a href=&#34;https://github.com/easystats/see&#34;&gt;&lt;strong&gt;see&lt;/strong&gt;&lt;/a&gt; package):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(see)

plot(p_direction(model))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_pd_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;from-p-direction-to-p-value&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;From &lt;em&gt;p&lt;/em&gt;-direction to &lt;em&gt;p&lt;/em&gt;-value&lt;/h2&gt;
&lt;p&gt;We can convert this value to a &lt;em&gt;p&lt;/em&gt;-value using the following function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pd_to_p(0.9880)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.024&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, we are not far from the frequentist &lt;em&gt;p&lt;/em&gt;-value!&lt;/p&gt;
&lt;p&gt;But again, we need to underline that the &lt;em&gt;p&lt;/em&gt;-direction has a &lt;strong&gt;different meaning and interpretation&lt;/strong&gt;. It refers to the &lt;em&gt;probability that the effect is positive or negative (depending on the median’s sign)&lt;/em&gt;. But like the &lt;em&gt;p&lt;/em&gt;-value, it cannot either be used to &lt;strong&gt;support a lack of an effect&lt;/strong&gt; (for that, &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/region_of_practical_equivalence.html&#34;&gt;ROPE-based indices&lt;/a&gt; or &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayes_factors.html&#34;&gt;Bayes factors&lt;/a&gt; might be more appropriate).&lt;/p&gt;
&lt;p&gt;Moreover, when using &lt;strong&gt;informative priors&lt;/strong&gt; centred at 0, a Bayesian analysis will always lead to “less significant” effects, as the prior will pull the posterior towards 0. This is a natural way of penalizing results, which &lt;strong&gt;is a good thing&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In conclusion, make sure you understand the indices you use (for instance by &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayestestR.html&#34;&gt;&lt;strong&gt;checking-out our gentle intro to Bayesian analysis&lt;/strong&gt;&lt;/a&gt;)!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;easystats&lt;/em&gt; is a new project in active development, looking for contributors and supporters. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;stay-tuned&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stay tuned&lt;/h2&gt;
&lt;p&gt;To be updated about the &lt;em&gt;upcoming features&lt;/em&gt; and cool R or data science stuff, you can &lt;strong&gt;follow the packages on GitHub&lt;/strong&gt; (click on one &lt;a href=&#34;https://github.com/easystats&#34;&gt;of the easystats package&lt;/a&gt;) and then on the &lt;strong&gt;Watch&lt;/strong&gt; button on the top right corner) as well as the &lt;strong&gt;easystats team on twitter and online&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/easystats4u&#34;&gt;@easystats4u&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/strengejacke&#34;&gt;@strengejacke&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34;&gt;@DominiqueMakowski&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/mattansb&#34;&gt;@mattansb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/patilindrajeets&#34;&gt;@IndrajeetPatil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/humanfactorsio&#34;&gt;@humanfactors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jonaslindeloev&#34;&gt;@lindeloev&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jacobandrewlong&#34;&gt;@jacob-long&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pdwaggoner.github.io/&#34;&gt;@pdwaggoner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/LDtrx&#34;&gt;@LeoDutriaux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>bayestestR</category>
      
            <category>p-value</category>
      
            <category>pd</category>
      
            <category>p-direction</category>
      
      
            <category>R</category>
      
            <category>bayestestR</category>
      
    </item>
    
    <item>
      <title>easystats: one year already. What&#39;s next?</title>
      <link>/blog/posts/easystats_oneyear/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/easystats_oneyear/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easystats/easystats/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;happy-birthday-easystats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Happy birthday easystats!&lt;/h2&gt;
&lt;p&gt;About a year ago, I &lt;a href=&#34;https://github.com/DominiqueMakowski&#34;&gt;(Dom)&lt;/a&gt; sadly realised that the R package I was maintaining (&lt;a href=&#34;https://github.com/neuropsychology/psycho.R&#34;&gt;&lt;em&gt;psycho&lt;/em&gt;&lt;/a&gt;) was drifting more and more away from its original scope, getting drown under a pile of unrelated and under-documented features that I kept on adding as my R skills improved. &lt;strong&gt;Something had to be done.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I decided to get in touch with &lt;a href=&#34;https://github.com/strengejacke&#34;&gt;Daniel&lt;/a&gt;, &lt;em&gt;aka&lt;/em&gt; &lt;strong&gt;strengejacke&lt;/strong&gt; (for mysterious and very confusing reasons), the author of the &lt;a href=&#34;https://github.com/strengejacke&#34;&gt;&lt;em&gt;sjverse&lt;/em&gt;&lt;/a&gt;, a collection of awesome packages which scope wasn’t too distant from my own one. Quickly, we realised that beyond facing similar issues, we shared the same vision: &lt;strong&gt;Make R stats easy again&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We were also agreeing on a possible way of reaching this goal. Build a new collection of packages that would work together to provide a smooth experience to getting stats, and all that entails, done in R (note that we preferred the workflow to be &lt;em&gt;easy&lt;/em&gt; rather than &lt;em&gt;tidy&lt;/em&gt;… ;p). Most importantly, we shared the same values, including a commitment to open-science, a desire for collaborative development, a focus on user- and beginner- friendliness, and a dedication to the Force.&lt;/p&gt;
&lt;p&gt;And just like that, &lt;a href=&#34;https://github.com/orgs/easystats/&#34;&gt;&lt;strong&gt;easystats was born&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But this project wouldn’t have grown, nor still exist, if we hadn’t manage to bring in the &lt;strong&gt;most talented people&lt;/strong&gt;, creating an awesome &lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;team&lt;/a&gt; which diversity in experience and skills offers an incredibly valuable resource. Shout-out to the ultimate Bayes master &lt;a href=&#34;https://github.com/mattansb&#34;&gt;@mattansb&lt;/a&gt;, to our socio-political expert &lt;a href=&#34;https://github.com/pdwaggoner&#34;&gt;@pdwaggoner&lt;/a&gt;, to &lt;a href=&#34;https://twitter.com/patilindrajeets&#34;&gt;@IndrajeetPatil&lt;/a&gt;, the compulsive model supporter and author of the famous &lt;a href=&#34;https://github.com/IndrajeetPatil/ggstatsplot&#34;&gt;&lt;em&gt;ggstatsplot&lt;/em&gt;&lt;/a&gt;, to our big-daddy-markdown-mate &lt;a href=&#34;https://twitter.com/humanfactorsio&#34;&gt;@humanfactors&lt;/a&gt;, to the best dinosaur stats explainer &lt;a href=&#34;https://twitter.com/jonaslindeloev&#34;&gt;@lindeloev&lt;/a&gt; and to the &lt;a href=&#34;https://github.com/jacob-long/interactions&#34;&gt;&lt;em&gt;interaction&lt;/em&gt;&lt;/a&gt; genius &lt;a href=&#34;https://twitter.com/jacobandrewlong&#34;&gt;@jacob-long&lt;/a&gt;. A big thank you to this great team. Make sure to check-out their awesome work and research!&lt;/p&gt;
&lt;p&gt;Together in one year, we created &lt;strong&gt;9 packages&lt;/strong&gt;, pushed 7 of them to &lt;strong&gt;CRAN&lt;/strong&gt; (which have now been downloaded more than &lt;strong&gt;half a million times&lt;/strong&gt; &lt;em&gt;(!!!)&lt;/em&gt;), wrote many &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;blogposts&lt;/strong&gt;&lt;/a&gt;, and made just about a thousand &lt;a href=&#34;https://raw.githubusercontent.com/easystats/easystats/master/man/figures/misc/notthememe.jpg&#34;&gt;memes&lt;/a&gt;. But most importantly, we all &lt;strong&gt;learned a lot&lt;/strong&gt;, as this project partly became the opportunity for us to drastically improve our R, stats, programming and light-saber skills. Moreover, it also ended up being a great occasion and place to have &lt;strong&gt;fun&lt;/strong&gt;, contribute to the &lt;strong&gt;community&lt;/strong&gt;, and become part of a &lt;strong&gt;network&lt;/strong&gt; of talented and open-minded people with similar interests. And that is, by far, one of the biggest take-away.&lt;/p&gt;
&lt;p&gt;And yet, although fun is good, it doesn’t make for a living (unless you’re Mr Bean). And the &lt;strong&gt;easystats&lt;/strong&gt; project also turned out to be a legit academic research project with legit academic outcomes. This year, we published &lt;strong&gt;3 papers&lt;/strong&gt; (&lt;a href=&#34;https://joss.theoj.org/papers/10.21105/joss.01412&#34;&gt;&lt;em&gt;insight&lt;/em&gt;&lt;/a&gt;]; &lt;a href=&#34;https://joss.theoj.org/papers/10.21105/joss.01541&#34;&gt;&lt;em&gt;bayestestR&lt;/em&gt;&lt;/a&gt; and &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.02767&#34;&gt;another Bayes-related one&lt;/a&gt;) related to easystats, and we plan on keeping up &lt;em&gt;at least&lt;/em&gt; that rhythm for the year to come &lt;em&gt;(now might be your chance to get involved ;)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Aside from publications, we also plan on releasing the remaining packages (What do I hear? “fixing &lt;a href=&#34;https://github.com/easystats/report&#34;&gt;&lt;em&gt;report&lt;/em&gt;&lt;/a&gt;”?), continue improving the existing ones and adding even more awesome features and documentation.&lt;/p&gt;
&lt;p&gt;All in all, &lt;strong&gt;easystats&lt;/strong&gt; is a living and breathing demonstration of how an open-science project can be born, keep growing and improving like an old wine. And the beauty, and tragedy, lies in the fact that it’s arguably against all the odds offered by the current academic system. We have &lt;strong&gt;no funding&lt;/strong&gt; (however, very interested in getting some… &lt;em&gt;*wink wink*&lt;/em&gt;), no initial publication goals, and no direct obligation or pressure to work to it. We are all contributing to it on our &lt;strong&gt;free time&lt;/strong&gt;, out of &lt;strong&gt;pure enthusiasm&lt;/strong&gt; and interest in making this place a lil’ bit better.&lt;/p&gt;
&lt;p&gt;So, as a closing note, because happiness is only useful when it is shared, we’d like to thank &lt;strong&gt;you, user of easystats&lt;/strong&gt;, for directly contributing to our passion. Cheers!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;…And if you’re not yet a user or a contributor… what are you waiting for?!&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;Note that &lt;em&gt;easystats&lt;/em&gt; is a new project in active development, looking for contributors and supporters. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;stay-tuned&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stay tuned&lt;/h2&gt;
&lt;p&gt;To be updated about the &lt;em&gt;upcoming features&lt;/em&gt; and cool R or data science stuff, you can &lt;strong&gt;follow the packages on GitHub&lt;/strong&gt; (click on one &lt;a href=&#34;https://github.com/easystats&#34;&gt;of the easystats package&lt;/a&gt;) and then on the &lt;strong&gt;Watch&lt;/strong&gt; button on the top right corner) as well as the &lt;strong&gt;easystats team on twitter and online&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/strengejacke&#34;&gt;@strengejacke&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34;&gt;@DominiqueMakowski&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/mattansb&#34;&gt;@mattansb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/patilindrajeets&#34;&gt;@IndrajeetPatil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/humanfactorsio&#34;&gt;@humanfactors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jonaslindeloev&#34;&gt;@lindeloev&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jacobandrewlong&#34;&gt;@jacob-long&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pdwaggoner.github.io/&#34;&gt;@pdwaggoner&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>aniversary</category>
      
      
            <category>R</category>
      
            <category>easystats</category>
      
    </item>
    
    <item>
      <title>Comparison of indices of significance in the Bayesian framework</title>
      <link>/blog/posts/bayestestr_evidence_ani/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_evidence_ani/</guid>
      <description>


&lt;p&gt;The &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;&lt;strong&gt;bayestestR&lt;/strong&gt;&lt;/a&gt; package has several functions to compute indices of effect existence and significance in a Bayesian framework, like &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/p_direction.html&#34;&gt;&lt;code&gt;p_direction()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/bayesfactor_parameters.html&#34;&gt;&lt;code&gt;bayesfactor_parameters()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The accuracy of these indices is affected by various sources of uncertainty, such as sample size or noise. &lt;a href=&#34;https://twitter.com/Dom_Makowski/status/1204027373542203394?s=20&#34;&gt;Using the package&lt;/a&gt;, we have created a small animation that demontrates how new evidence updates the posterior distribution and thereby indices of existence and significance:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easystats/easystats/master/man/figures/bayestestR/evidence_accumulation.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you’d like to know more (statistical) details about these indices, we have recently published a paper with a simulation study (available for free!), demonstrating how such indices behave in the context of different sources of uncertainty:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Makowski, D., Ben-Shachar, M. S., Chen, S. H., &amp;amp; Lüdecke, D. (2019). &lt;em&gt;Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology, 10&lt;/em&gt;, 2767. doi: &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.02767&#34;&gt;10.3389/fpsyg.2019.02767&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this paper, you’ll also find fancy figures like this one, showing the relationship between Bayesian indices and the frequentist &lt;em&gt;p&lt;/em&gt;-value:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easystats/easystats/master/man/figures/bayestestR/Figure4-small.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/p&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>bayestestR</category>
      
      
            <category>R</category>
      
            <category>bayestestR</category>
      
    </item>
    
    <item>
      <title>News from easystats: updated parameters and see packages.</title>
      <link>/blog/posts/parameters_and_see_update/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/parameters_and_see_update/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/parameters/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;img src=&#34;https://github.com/easystats/see/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;new-features-of-the-parameters-and-see-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;New Features of the parameters and see Package&lt;/h2&gt;
&lt;p&gt;We’re excited to announce some news from the &lt;a href=&#34;https://github.com/easystats/easystats&#34;&gt;easystats-project&lt;/a&gt;. Two packages were updated recently, the &lt;a href=&#34;https://easystats.github.io/parameters&#34;&gt;&lt;strong&gt;parameters&lt;/strong&gt;-package&lt;/a&gt; and our visualization-toolbox, the &lt;a href=&#34;http://easystats.github.io/see&#34;&gt;&lt;strong&gt;see&lt;/strong&gt;-package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before we start introducing some of the new features, we’d like to explain why you need the &lt;strong&gt;see&lt;/strong&gt;-package to create plots for functions from other &lt;em&gt;easystats&lt;/em&gt; packages. So, the &lt;strong&gt;see&lt;/strong&gt;-package not only includes additional geoms, color scales and themes for &lt;strong&gt;ggplot2&lt;/strong&gt;, but - maybe more important - also provides &lt;code&gt;plot()&lt;/code&gt;-methods for many functions from the various &lt;em&gt;easystats&lt;/em&gt; packages. By separating the plotting functionality from our core packages, packages from the easystats-project don’t rely nor import any other packages! This means that you can safely use them as dependencies in your own packages, without the risk of butterfly effects (a small change in a distant downstream dependency with unexpected upstream consequences).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;print-and-plot-your-model-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Print and Plot your Model Parameters&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://easystats.github.io/parameters/reference/model_parameters.html&#34;&gt;&lt;code&gt;model_parameters()&lt;/code&gt;&lt;/a&gt; function in the &lt;strong&gt;parameters&lt;/strong&gt;-package is simlar to &lt;code&gt;broom::tidy()&lt;/code&gt; - it returns a summary of the model parameters as a clean, consistent data frame. &lt;a href=&#34;https://easystats.github.io/parameters/reference/standardize_names.html&#34;&gt;&lt;code&gt;standardize_names()&lt;/code&gt;&lt;/a&gt; can be used to return a data frame with column names as they are used in other packages (like &lt;strong&gt;broom&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;model_parameters()&lt;/code&gt; supports many different models, including mixed or Bayesian regression models. It comes with nice &lt;code&gt;print()&lt;/code&gt; and &lt;code&gt;plot()&lt;/code&gt; methods.&lt;/p&gt;
&lt;div id=&#34;examples---zero-inflated-mixed-models-with-glmmtmb&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples - Zero Inflated Mixed Models with glmmTMB&lt;/h3&gt;
&lt;p&gt;The first example is a zero-inflated mixed model, fitted with the &lt;strong&gt;glmmTMB&lt;/strong&gt;-package. &lt;code&gt;model_parameters()&lt;/code&gt; creates separate tables for different model components (like zero-inflated components).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(glmmTMB)
data(Salamanders)
model &amp;lt;- glmmTMB(
  count ~ spp + mined + (1 | site),
  ziformula = ~mined,
  family = poisson(),
  data = Salamanders
)

model_parameters(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Fixed Effects component
## 
## Parameter   | Coefficient |   SE |         95% CI |     z |  df |      p
## ------------------------------------------------------------------------
## (Intercept) |       -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 633 | 0.194 
## spp [PR]    |       -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | 633 | &amp;lt; .001
## spp [DM]    |        0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 633 | 0.051 
## spp [EC-A]  |       -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 633 | 0.006 
## spp [EC-L]  |        0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | 633 | &amp;lt; .001
## spp [DES-L] |        0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | 633 | &amp;lt; .001
## spp [DF]    |        0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 633 | 0.435 
## mined [no]  |        1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | 633 | &amp;lt; .001
## 
## # Zero-Inflated component
## 
## Parameter   | Coefficient |   SE |         95% CI |     z |  df |      p
## ------------------------------------------------------------------------
## (Intercept) |        0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 633 | 0.004 
## mined [no]  |       -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | 633 | &amp;lt; .001&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If only a specific part of the model should be shown, use the &lt;code&gt;component&lt;/code&gt;-argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_parameters(model, component = &amp;quot;zero_inflated&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter   | Coefficient |   SE |         95% CI |     z |  df |      p
## ------------------------------------------------------------------------
## (Intercept) |        0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 633 | 0.004 
## mined [no]  |       -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | 633 | &amp;lt; .001&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;plot()&lt;/code&gt; creates a so called “forest plot”. In case of models with multiple components, parameters are separated into facets by model component.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result &amp;lt;- model_parameters(model)
plot(result)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/parameters_and_see_update_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;examples---bayesian-mixed-models-with-brms&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples - Bayesian Mixed Models with brms&lt;/h3&gt;
&lt;p&gt;For the next example, we download a pre-compiled &lt;strong&gt;brms&lt;/strong&gt; model to save computation time. For Bayesian models, by default, only “fixed” effects are shown. Using &lt;code&gt;effects = &#34;all&#34;&lt;/code&gt; and &lt;code&gt;component = &#34;all&#34;&lt;/code&gt; allows us to display random effects and the parameters of the zero-inflated model part as well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We download the model to save computation time. Here is the code
# to refit the exact model used below...

# zinb &amp;lt;- read.csv(&amp;quot;http://stats.idre.ucla.edu/stat/data/fish.csv&amp;quot;)
# set.seed(123)
# model &amp;lt;- brm(bf(
#     count ~ persons + child + camper + (1 | persons),
#     zi ~ child + camper + (1 | persons)
#   ),
#   data = zinb,
#   family = zero_inflated_poisson()
# )
brms_model &amp;lt;- insight::download_model(&amp;quot;brms_zi_2&amp;quot;)
result &amp;lt;- model_parameters(brms_model, effects = &amp;quot;all&amp;quot;, component = &amp;quot;all&amp;quot;)

result&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Fixed Effects (Count Model) 
## 
## Parameter   | Median |         89% CI |     pd | % in ROPE |  ESS |  Rhat
## -------------------------------------------------------------------------
## (Intercept) |  -0.84 | [-1.44, -0.29] | 96.43% |     2.77% |  562 | 1.009
## persons     |   0.84 | [ 0.66,  1.06] |   100% |        0% |  382 | 1.010
## child       |  -1.15 | [-1.29, -0.98] |   100% |        0% | 1089 | 1.002
## camper      |   0.73 | [ 0.58,  0.89] |   100% |        0% | 2724 | 1.000
## 
## # Fixed Effects (Zero-Inflated Model) 
## 
## Parameter   | Median |         89% CI |     pd | % in ROPE |  ESS |  Rhat
## -------------------------------------------------------------------------
## (Intercept) |  -0.64 | [-1.93,  0.52] | 83.15% |     6.95% |  845 | 1.001
## child       |   1.88 | [ 1.40,  2.43] |   100% |        0% | 2322 | 1.001
## camper      |  -0.83 | [-1.41, -0.24] | 98.95% |     1.70% | 2277 | 1.001
## 
## # Random Effects (Count Model) 
## 
## Parameter   | Median |        89% CI |     pd | % in ROPE | ESS |  Rhat
## -----------------------------------------------------------------------
## persons.1   |  -0.01 | [-0.38, 0.28] | 55.33% |    60.50% | 572 | 1.009
## persons.2   |   0.02 | [-0.17, 0.30] | 61.88% |    65.62% | 691 | 1.008
## persons.3   |  -0.02 | [-0.26, 0.18] | 61.27% |    67.90% | 340 | 1.011
## persons.4   |   0.00 | [-0.32, 0.33] | 51.38% |    62.12% | 287 | 1.011
## (Intercept) |   0.13 | [ 0.00, 0.50] |   100% |    42.60% | 311 | 1.013
## 
## # Random Effects (Zero-Inflated Model) 
## 
## Parameter    | Median |         89% CI |     pd | % in ROPE | ESS |  Rhat
## -------------------------------------------------------------------------
## persons.1    |   1.28 | [ 0.08,  2.70] | 95.73% |     2.15% | 811 | 1.001
## persons.2    |   0.25 | [-0.90,  1.57] | 66.45% |    12.72% | 759 | 1.001
## persons.3    |  -0.18 | [-1.51,  1.01] | 59.67% |    11.28% | 871 | 1.001
## persons.4    |  -1.29 | [-2.62, -0.01] | 94.85% |     1.85% | 912 | 1.000
## zi_Intercept |   1.49 | [ 0.44,  3.33] |   100% |     0.02% | 848 | 1.002&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;plot()&lt;/code&gt; now creates four facets by default. Note that plots from the &lt;strong&gt;parameters&lt;/strong&gt;-package create forest plots. If you prefer plots that show the complete posterior distribution, you may rather use functions from the &lt;strong&gt;bayestestRR&lt;/strong&gt;-package, as shown &lt;a href=&#34;https://easystats.github.io/see/articles/bayestestR.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(result)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/parameters_and_see_update_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can modify the layout with &lt;code&gt;n_columns&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(result, n_columns = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/parameters_and_see_update_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;examples---meta-analysis-with-metafor&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples - Meta-Analysis with metafor&lt;/h3&gt;
&lt;p&gt;Even results from meta-analyses, using the &lt;strong&gt;metafor&lt;/strong&gt;-package, can be visualized with &lt;strong&gt;parameters&lt;/strong&gt; and &lt;strong&gt;see&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
d &amp;lt;- data.frame(
  effectsize = c(-0.393, 0.675, 0.282, -1.398),
  standarderror = c(0.317, 0.317, 0.13, 0.36)
)

ma &amp;lt;- rma(yi = effectsize, sei = standarderror, method = &amp;quot;REML&amp;quot;, data = d)
result &amp;lt;- model_parameters(ma)

result&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter | Coefficient |   SE |         95% CI |     z |      p | Weight
## -------------------------------------------------------------------------
## Study 1   |       -0.39 | 0.32 | [-1.01,  0.23] | -1.24 | 0.215  |   9.95
## Study 2   |        0.68 | 0.32 | [ 0.05,  1.30] |  2.13 | 0.033  |   9.95
## Study 3   |        0.28 | 0.13 | [ 0.03,  0.54] |  2.17 | 0.030  |  59.17
## Study 4   |       -1.40 | 0.36 | [-2.10, -0.69] | -3.88 | &amp;lt; .001 |   7.72
## Overall   |       -0.18 | 0.44 | [-1.05,  0.68] | -0.42 | 0.676  |&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Above you see the coefficients, their standard errors and the “weight”, based on the inverse variance. When you plot the results, the dot-geoms have different sizes, depending on the weight of the study (similar to &lt;code&gt;metafor::forest()&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(result)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/parameters_and_see_update_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Check out&lt;/strong&gt; more examples and documentation &lt;a href=&#34;https://easystats.github.io/parameters/&#34;&gt;&lt;strong&gt;here (for &lt;em&gt;parameters&lt;/em&gt;&lt;/strong&gt;)&lt;/a&gt; and &lt;a href=&#34;https://easystats.github.io/see/&#34;&gt;&lt;strong&gt;here (for &lt;em&gt;see&lt;/em&gt;&lt;/strong&gt;)&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;Note that &lt;em&gt;easystats&lt;/em&gt; is a new project in active development, looking for contributors and supporters. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>parameters</category>
      
            <category>coefficients</category>
      
            <category>see</category>
      
            <category>visualization</category>
      
      
            <category>R</category>
      
            <category>parameters</category>
      
            <category>see</category>
      
    </item>
    
    <item>
      <title>More models, more features: what&#39;s new in &#39;parameters&#39; 0.2.0</title>
      <link>/blog/posts/parameters_v2/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/parameters_v2/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/parameters/raw/master/man/figures/figure1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats project&lt;/strong&gt;&lt;/a&gt; continues to grow, expanding its capabilities and features, and the &lt;a href=&#34;https://github.com/easystats/parameters&#34;&gt;&lt;strong&gt;&lt;code&gt;parameters&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; package 0.2.0 update is now on CRAN.&lt;/p&gt;
&lt;p&gt;The primary goal of this package is to provide utilities for &lt;strong&gt;processing the parameters&lt;/strong&gt; of various statistical models. It is useful for end-users as well as developers, as it is a &lt;strong&gt;lightweight&lt;/strong&gt; and open-developed package.&lt;/p&gt;
&lt;p&gt;The main function, &lt;a href=&#34;https://easystats.github.io/parameters/articles/model_parameters.html&#34;&gt;&lt;code&gt;model_parameters()&lt;/code&gt;&lt;/a&gt;, can be seen as an alternative to &lt;code&gt;broom::tidy()&lt;/code&gt;. However, the package also include many more useful &lt;a href=&#34;https://easystats.github.io/parameters/reference/index.html&#34;&gt;features&lt;/a&gt;, some of which are described in our &lt;strong&gt;improved documentation&lt;/strong&gt;:&lt;/p&gt;
&lt;div id=&#34;improved-documentation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Improved Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Parameters Description&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/parameters/articles/model_parameters.html&#34;&gt;Guide to parameters description&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Parameters Engineering&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/parameters/articles/bootstrapping.html&#34;&gt;Guide to bootstrapped parameters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/parameters/articles/standardization.html&#34;&gt;Guide to standardized parameters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Parameters Selection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/parameters/articles/parameters_selection.html&#34;&gt;Guide to parameters selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dimension Reduction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/parameters/articles/parameters_reduction.html&#34;&gt;Guide to feature reduction (PCA, cMDS, ICA…)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/parameters/articles/efa_cfa.html&#34;&gt;Guide to structural models (EFA, CFA, SEM…)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;improved-support&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Improved Support&lt;/h2&gt;
&lt;p&gt;Besides stabilizing and improving the functions for the most popular models (&lt;code&gt;glm()&lt;/code&gt;, &lt;code&gt;glmer()&lt;/code&gt;, &lt;code&gt;stan_glm()&lt;/code&gt;, &lt;code&gt;psych&lt;/code&gt; and &lt;code&gt;lavaan&lt;/code&gt;…), the functions &lt;code&gt;p_value()&lt;/code&gt;, &lt;code&gt;ci()&lt;/code&gt;, &lt;code&gt;standard_error()&lt;/code&gt;, &lt;code&gt;standardize()&lt;/code&gt; and most importantly &lt;code&gt;model_parameters()&lt;/code&gt; now support many more model objects, including mixed models from packages &lt;em&gt;nlme&lt;/em&gt;, &lt;em&gt;glmmTMB&lt;/em&gt; or &lt;em&gt;GLMMadaptive&lt;/em&gt;, zero-inflated models from package &lt;em&gt;pscl&lt;/em&gt;, other regression types from packages &lt;em&gt;gam&lt;/em&gt; or &lt;em&gt;mgcv&lt;/em&gt;, fixed effects regression models from &lt;em&gt;panelr&lt;/em&gt;, &lt;em&gt;lfe&lt;/em&gt;, &lt;em&gt;feisr&lt;/em&gt; or &lt;em&gt;plm&lt;/em&gt;, and structural models from &lt;em&gt;FactoMineR&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;improved-printing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Improved Printing&lt;/h2&gt;
&lt;p&gt;For models with special components, in particular zero-inflated models, &lt;code&gt;model_parameters()&lt;/code&gt; separates these components for a clearer output.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # Fixed Effects component
## 
## Parameter   | Coefficient |   SE |         95% CI |     z |  df |      p
## ------------------------------------------------------------------------
## (Intercept) |       -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 633 | 0.194 
## spp [PR]    |       -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | 633 | &amp;lt; .001
## spp [DM]    |        0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 633 | 0.051 
## spp [EC-A]  |       -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 633 | 0.006 
## spp [EC-L]  |        0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | 633 | &amp;lt; .001
## spp [DES-L] |        0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | 633 | &amp;lt; .001
## spp [DF]    |        0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 633 | 0.435 
## mined [no]  |        1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | 633 | &amp;lt; .001
## 
## # Zero-Inflated component
## 
## Parameter   | Coefficient |   SE |         95% CI |     z |  df |      p
## ------------------------------------------------------------------------
## (Intercept) |        0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 633 | 0.004 
## mined [no]  |       -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | 633 | &amp;lt; .001&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;join-the-team&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Join the team&lt;/h2&gt;
&lt;p&gt;There is still room for improvement, and some new exciting features are already planned. Feel free to let us know how we could further improve this package!&lt;/p&gt;
&lt;p&gt;Note that &lt;em&gt;easystats&lt;/em&gt; is a new project in active development, looking for contributors and supporters. Thus, do not hesitate to contact one of &lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;us&lt;/a&gt; if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>parameters</category>
      
            <category>broom</category>
      
            <category>coefficients</category>
      
      
            <category>R</category>
      
            <category>parameters</category>
      
    </item>
    
    <item>
      <title>parameters: a powerful and lightweight alternative to broom to describe your models&#39; coefficients</title>
      <link>/blog/posts/parameters_presentation/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/parameters_presentation/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/parameters/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Okay, &lt;em&gt;“an alternative to broom”&lt;/em&gt; might be a bit of an &lt;strong&gt;overstatement&lt;/strong&gt; &lt;em&gt;(at least for now…)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But the &lt;a href=&#34;https://github.com/easystats/parameters&#34;&gt;&lt;strong&gt;&lt;code&gt;parameters&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; package, finally on CRAN, already has some cool features!&lt;/p&gt;
&lt;div id=&#34;parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;parameters&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;We&lt;/a&gt; have recently decided to collaborate around the &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats project&lt;/strong&gt;&lt;/a&gt;, a set of packages designed to make your life &lt;em&gt;easier&lt;/em&gt;. This project encompasses several packages, devoted for instance to &lt;a href=&#34;https://github.com/easystats/insight&#34;&gt;model internal access&lt;/a&gt;, &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;Bayesian analysis&lt;/a&gt;, as well as &lt;a href=&#34;https://github.com/easystats/performance&#34;&gt;indices of model performance and quality&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/easystats/parameters&#34;&gt;&lt;strong&gt;&lt;code&gt;parameters&#39;&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; primary goal is to provide utilities for processing the parameters of various statistical models. Beyond computing &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;-values&lt;/strong&gt;, &lt;strong&gt;CIs&lt;/strong&gt;, &lt;strong&gt;Bayesian indices&lt;/strong&gt; and other measures for a wide variety of models, this package implements features like &lt;strong&gt;standardization&lt;/strong&gt; or &lt;strong&gt;bootstrapping&lt;/strong&gt; of parameters and models, &lt;strong&gt;feature reduction&lt;/strong&gt; (feature extraction and variable selection) as well as conversion between indices of &lt;strong&gt;effect size&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The main function of the package is &lt;code&gt;model_parameters()&lt;/code&gt;, which allows you to extract the parameters and their characteristics from various models in a consistent way. It can be considered as a lightweight alternative to &lt;a href=&#34;https://github.com/tidymodels/broom&#34;&gt;&lt;code&gt;broom::tidy()&lt;/code&gt;&lt;/a&gt;, with some notable differences:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The names of the returned dataframe are &lt;strong&gt;specific&lt;/strong&gt; to their content. For instance, the column containing the statistic is named following the statistic name, i.e., &lt;em&gt;t&lt;/em&gt;, &lt;em&gt;z&lt;/em&gt;, etc., instead of a generic name such as &lt;em&gt;statistic&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;It is able to compute or extract indices not available by default, such as &lt;strong&gt;&lt;em&gt;p&lt;/em&gt; values&lt;/strong&gt;, &lt;strong&gt;CIs&lt;/strong&gt;, etc.&lt;/li&gt;
&lt;li&gt;It includes &lt;strong&gt;feature engineering&lt;/strong&gt; capabilities, including &lt;a href=&#34;https://easystats.github.io/parameters/articles/bootstrapping.html&#34;&gt;&lt;strong&gt;bootstrapping&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://easystats.github.io/parameters/articles/standardization.html&#34;&gt;&lt;strong&gt;standardization&lt;/strong&gt;&lt;/a&gt; of parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;div id=&#34;anovas&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ANOVAs&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- iris
df$Sepal.Big &amp;lt;- ifelse(df$Sepal.Width &amp;gt;= 3, &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;)

model &amp;lt;- aov(Sepal.Length ~ Sepal.Big, data = df)
model_parameters(model, eta_squared = &amp;quot;partial&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter | Sum_Squares |  df | Mean_Square |    F |     p | Eta_Sq (partial)
## -----------------------------------------------------------------------------
## Sepal.Big |        1.10 |   1 |        1.10 | 1.61 | 0.207 |             0.01
## Residuals |      101.07 | 148 |        0.68 |      |       |&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mixed-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Mixed models&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)

model &amp;lt;- lmer(Sepal.Width ~ Petal.Length + Petal.Width + (1|Species), data = iris)
model_parameters(model, standardize = &amp;quot;refit&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter    | Coefficient |   SE |        95% CI |    t |  df |      p
## -----------------------------------------------------------------------
## (Intercept)  |        0.00 | 1.51 | [-2.96, 2.96] | 0.00 | 145 | 1.000 
## Petal.Length |        0.59 | 0.26 | [ 0.08, 1.10] | 2.26 | 145 | 0.024 
## Petal.Width  |        1.07 | 0.24 | [ 0.60, 1.53] | 4.49 | 145 | &amp;lt; .001&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And you can also &lt;strong&gt;directly plot the parameters&lt;/strong&gt; with the see package!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(see)

lmer(Sepal.Width ~ Petal.Length * Petal.Width + (1|Species), data = iris) %&amp;gt;% 
  model_parameters() %&amp;gt;% 
  plot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/parameters_presentation_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bayesian models&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstanarm)

model &amp;lt;- stan_glm(mpg ~ wt + cyl, data = mtcars)
model_parameters(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parameter   | Median |         89% CI |     pd | % in ROPE |  Rhat |  ESS |               Prior
## -----------------------------------------------------------------------------------------------
## (Intercept) |  39.65 | [37.16, 42.75] |   100% |        0% | 1.000 | 5136 | Normal (0 +- 60.27)
## wt          |  -3.17 | [-4.45, -1.94] |   100% |     0.12% | 1.000 | 2425 | Normal (0 +- 15.40)
## cyl         |  -1.51 | [-2.13, -0.80] | 99.98% |     1.85% | 1.001 | 2479 |  Normal (0 +- 8.44)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/parameters/&#34;&gt;&lt;strong&gt;more examples and documentation here!&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;There is definitely room for improvement, and some new exciting features are already planned. Feel free to let us know how we could further improve this package!&lt;/p&gt;
&lt;p&gt;Note that &lt;em&gt;easystats&lt;/em&gt; is a new project in active development, looking for contributors and supporters. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>parameters</category>
      
            <category>standardize</category>
      
            <category>coefficients</category>
      
      
            <category>R</category>
      
            <category>parameters</category>
      
    </item>
    
    <item>
      <title>Check your (Mixed) Model for Multicollinearity with &#39;performance&#39;</title>
      <link>/blog/posts/performance_check_collinearity/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/performance_check_collinearity/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/performance/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The goal of &lt;a href=&#34;https://github.com/easystats/performance&#34;&gt;&lt;strong&gt;performance&lt;/strong&gt;&lt;/a&gt; is to provide lightweight tools to assess and check the quality of your model. It includes functions such as &lt;a href=&#34;https://easystats.github.io/performance/reference/r2.html&#34;&gt;&lt;code&gt;r2()&lt;/code&gt;&lt;/a&gt; for many models (including logistic, mixed and Bayesian models), &lt;a href=&#34;https://easystats.github.io/performance/reference/icc.html&#34;&gt;&lt;code&gt;icc()&lt;/code&gt;&lt;/a&gt; or helpers to &lt;a href=&#34;https://easystats.github.io/performance/reference/check_convergence.html&#34;&gt;&lt;code&gt;check_convergence()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://easystats.github.io/performance/reference/check_overdispersion.html&#34;&gt;&lt;code&gt;check_overdipsersion()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://easystats.github.io/performance/reference/check_zeroinflation.html&#34;&gt;&lt;code&gt;check_zero-inflation()&lt;/code&gt;&lt;/a&gt; (see a complete list of functions &lt;a href=&#34;https://easystats.github.io/performance/reference/index.html&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In this posting, we want to focus on &lt;em&gt;multicollinearity&lt;/em&gt;. Multicollinearity “is a phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others” (&lt;a href=&#34;https://en.wikipedia.org/wiki/Multicollinearity&#34;&gt;source&lt;/a&gt;), i.e. two or more predictors are more or less strongly correlated (also described as &lt;em&gt;non-independent covariates&lt;/em&gt;). Multicollinearity may lead to severly biased regression coefficients and standard errors.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/performance/reference/check_convergence.html&#34;&gt;&lt;code&gt;check_collinearity()&lt;/code&gt;&lt;/a&gt; checks your model predictors for collinearity. The function works for “simple” models, but also for mixed models, including zero-inflated mixed models fitted with the &lt;strong&gt;glmmTMB&lt;/strong&gt; or &lt;strong&gt;GLMMadapative&lt;/strong&gt; packages. The function provides a nice &lt;code&gt;print()&lt;/code&gt; and &lt;code&gt;plot()&lt;/code&gt; method, and examples are shown below.&lt;/p&gt;
&lt;div id=&#34;check-linear-models-for-multicollinearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Check Linear Models for Multicollinearity&lt;/h2&gt;
&lt;p&gt;First, we fit a simple linear model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(performance)

# fit model
data(mtcars)
model &amp;lt;- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s check the model. Below you see two columns in the output, one indicating the &lt;em&gt;variance inflation factor&lt;/em&gt;, &lt;code&gt;VIF&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# now check for multicollinearity
check_collinearity(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Check for Multicollinearity
## 
## Low Correlation
## 
##  Parameter  VIF Increased SE
##       gear 1.53         1.24
## 
## Moderate Correlation
## 
##  Parameter  VIF Increased SE
##         wt 5.05         2.25
##        cyl 5.41         2.33
##       disp 9.97         3.16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variance inflation factor is a measure to analyze the magnitude of multicollinearity of model terms. A VIF less than 5 indicates a low correlation of that predictor with other predictors. A value between 5 and 10 indicates a moderate correlation, while VIF values larger than 10 are a sign for high, not tolerable correlation of model predictors.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Increased SE&lt;/code&gt; column in the output indicates how much larger the standard error is due to the correlation with other predictors.&lt;/p&gt;
&lt;p&gt;Now let’s plot the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot results
x &amp;lt;- check_collinearity(model)
plot(x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/performance_check_collinearity_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;check-zero-inflated-mixed-models-for-multicollinearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Check Zero-Inflated Mixed Models for Multicollinearity&lt;/h2&gt;
&lt;p&gt;For models with zero-inflation component, multicollinearity may happen both in the &lt;em&gt;count&lt;/em&gt; as well as the &lt;em&gt;zero-inflation&lt;/em&gt; component. By default, &lt;code&gt;check_collinearity()&lt;/code&gt; checks the complete model, however, you can check only certain components of the model using the &lt;code&gt;component&lt;/code&gt;-argument. In the following example, we will focus on the complete model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(glmmTMB)
data(Salamanders)

# create highly correlated pseudo-variable
set.seed(1)
Salamanders$cover2 &amp;lt;-
  Salamanders$cover * runif(n = nrow(Salamanders), min = .7, max = 1.3)

# fit mixed model with zero-inflation
model &amp;lt;- glmmTMB(
  count ~ spp + mined + cover + cover2 + (1 | site), 
  ziformula = ~ spp + mined, 
  family = truncated_poisson, 
  data = Salamanders
)

# now check for multicollinearity
check_collinearity(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Check for Multicollinearity
## 
## * conditional component:
## 
## Low Correlation
## 
##  Parameter  VIF Increased SE
##        spp 1.07         1.04
##      mined 1.17         1.08
## 
## High Correlation
## 
##  Parameter   VIF Increased SE
##      cover 19.30         4.39
##     cover2 19.12         4.37
## 
## * zero inflated component:
## 
## Low Correlation
## 
##  Parameter  VIF Increased SE
##        spp 1.08         1.04
##      mined 1.08         1.04&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the &lt;code&gt;print()&lt;/code&gt; method separates the results into the &lt;em&gt;count&lt;/em&gt; and &lt;em&gt;zero-inflated&lt;/em&gt; model components for a clearer output. Similar, &lt;code&gt;plot()&lt;/code&gt; produces facets for each components, so it’s easier to understand.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(check_collinearity(model))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/performance_check_collinearity_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;remedies-for-multicollinearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Remedies for Multicollinearity&lt;/h2&gt;
&lt;p&gt;Multicollinearity can have different reasons. Probably in many cases it will help to center or standardize the predictors. Sometimes the only way to avoid multicollinearity is to remove one of the predictors with a very high VIF value. Collecting more data may also help, but this is of course not always possible.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;join-easystats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;join easystats&lt;/h2&gt;
&lt;p&gt;Note that &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;&lt;em&gt;easystats&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt; is a new project in active development, and feedback, suggestions, comments are very welcome! Do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>performance</category>
      
            <category>multicollinearity</category>
      
      
            <category>R</category>
      
            <category>performance</category>
      
    </item>
    
    <item>
      <title>Testing Contrasts from Bayesian Models with &#39;emmeans&#39; and &#39;bayestestR&#39;</title>
      <link>/blog/posts/bayestestr_emmeans/</link>
      <pubDate>Thu, 06 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_emmeans/</guid>
      <description>


&lt;div id=&#34;the-problem-with-null-effects&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Problem with Null Effects&lt;/h1&gt;
&lt;p&gt;Say you fit an ANOVA model, predicting the time it takes to solve a puzzle from its shape (round / square) and whether it was colored or black and white, and you found that one of the estimated effects, in this case the interaction, was not significant. Say even that it was as non-significant as can be, with &lt;strong&gt;&lt;em&gt;p&lt;/em&gt; = 1.00&lt;/strong&gt;!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;options(contrasts = c(&amp;#39;contr.sum&amp;#39;, &amp;#39;contr.poly&amp;#39;))

data(&amp;quot;puzzles&amp;quot;, package = &amp;quot;BayesFactor&amp;quot;)
aov_model &amp;lt;- aov(RT ~ shape*color + Error(ID/(shape*color)), data = puzzles)

summary(aov_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Error: ID
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## Residuals 11    226    20.6               
## 
## Error: ID:shape
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)  
## shape      1   12.0   12.00    7.54  0.019 *
## Residuals 11   17.5    1.59                 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Error: ID:color
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)   
## color      1   12.0   12.00    13.9 0.0033 **
## Residuals 11    9.5    0.86                  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Error: ID:shape:color
##             Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## shape:color  1    0.0    0.00       0      1
## Residuals   11   30.5    2.77&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You look at your data, as you were taught to do, and it really does seems like the effect of color &lt;em&gt;is not&lt;/em&gt; moderated by shape (and vice versa):
&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_emmeans_files/figure-html/plot_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But what does this mean? &lt;strong&gt;Can you infer that there isn’t interaction?&lt;/strong&gt; Are the two simple effects of color truly identical?&lt;/p&gt;
&lt;p&gt;Classical statistics has no answer for us here - when the &lt;em&gt;p&lt;/em&gt;-value is less than alpha (typically 5%) we can reject the null hypothesis, but when &lt;strong&gt;&lt;em&gt;p&lt;/em&gt; &amp;gt; .05&lt;/strong&gt;, even a lot bigger than 5%, classical (frequentists) statistics &lt;strong&gt;do not allow to infer that the null is true&lt;/strong&gt;. For this, we need to go Bayesian!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;going-bayesian&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Going Bayesian&lt;/h1&gt;
&lt;p&gt;One of the (many) strengths of Bayesian statistics is its ability to support the null hypothesis. Let us fit a &lt;strong&gt;Bayesian mixed model equivalent to the repeated measures ANOVA&lt;/strong&gt; above, manually specifying weakly informative priors on its effects:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstanarm)
stan_model &amp;lt;- stan_lmer(RT ~ shape*color + (1 | ID), data = puzzles,
                        prior = cauchy(0,c(0.707,0.707,0.5),          # as per Rouder et al., 2012
                        prior_intercept = student_t(3,0,10),          # weakly informative
                        prior_aux = exponential(.1),                  # weakly informative
                        prior_covariance = decov(1,1,1,1))            # weakly informative&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the fantastic &lt;strong&gt;&lt;code&gt;emmeans&lt;/code&gt;&lt;/strong&gt; package, we can explore and extract marginal effects and estimates from our fitted model. For example, we can estimate the main effect for color:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c_color_main &amp;lt;- pairs(emmeans(stan_model, ~ color))
c_color_main&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  contrast              estimate lower.HPD upper.HPD
##  color - monochromatic   -0.944     -1.66    -0.128
## 
## Point estimate displayed: median 
## HPD interval probability: 0.95&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also estimate (based on posterior draws) the difference between the two simple effects for color between the levels of shape:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;em_color_simple &amp;lt;- emmeans(stan_model, ~color * shape)
pairs(em_color_simple, by = &amp;quot;shape&amp;quot;) # simple effects for color&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## shape = round:
##  contrast              estimate lower.HPD upper.HPD
##  color - monochromatic   -0.940     -1.99     0.115
## 
## shape = square:
##  contrast              estimate lower.HPD upper.HPD
##  color - monochromatic   -0.949     -1.98     0.149
## 
## Point estimate displayed: median 
## HPD interval probability: 0.95&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c_color_shape_interaction &amp;lt;- contrast(em_color_simple, interaction = c(&amp;quot;pairwise&amp;quot;,&amp;quot;pairwise&amp;quot;))
c_color_shape_interaction&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  color_pairwise        shape_pairwise estimate lower.HPD upper.HPD
##  color - monochromatic round - square -0.00364      -1.5      1.36
## 
## Point estimate displayed: median 
## HPD interval probability: 0.95&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, the simple effects are indeed similar, and the difference between them seems very close to 0. Can we quantify the evidence &lt;em&gt;for the null&lt;/em&gt;?&lt;/p&gt;
&lt;div id=&#34;quantifying-evidence-for-the-null&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quantifying Evidence for the Null&lt;/h2&gt;
&lt;p&gt;One way to quantify evidence in the Bayesian framework is to calculate a &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayes_factors.html&#34;&gt;&lt;strong&gt;Bayes factor&lt;/strong&gt;&lt;/a&gt; - a measure of relative evidence in favor of one model over another. In our case, we would like to compare a model with an interaction to a model without an interaction. Though we could fit the model without the interaction and compare the two with &lt;code&gt;bayesfactor_models()&lt;/code&gt;, we’ll use a close approximation using the Savage-Dickey density ratio, which allows for more flexibility. To this end we can use (from &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;version 0.2.1, available on GitHub&lt;/a&gt;) &lt;code&gt;describe_posterior()&lt;/code&gt; to… well… describe our &lt;code&gt;emmeans&lt;/code&gt; estimates’ posterior distribution, and by comparing the density of the null value (here 0) between the prior and posterior, we can compute the Savage-Dickey Bayes factor! (Note that we will need to pass the original model via &lt;code&gt;bf_prior&lt;/code&gt; to allow the extraction or prior draw.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# combine all estimates of interest to one object:
c_color_all &amp;lt;- rbind(c_color_main,
                     c_color_shape_interaction)
c_color_all&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  contrast              color_pairwise        shape_pairwise estimate lower.HPD
##  color - monochromatic .                     .                -0.944     -1.66
##  .                     color - monochromatic round - square   -0.004     -1.50
##  upper.HPD
##     -0.128
##      1.362
## 
## Point estimate displayed: median 
## HPD interval probability: 0.95&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;describe_posterior(c_color_all,
                   estimate = &amp;quot;median&amp;quot;, dispersion = TRUE,
                   ci = .9, ci_method = &amp;quot;hdi&amp;quot;,
                   test = c(&amp;quot;bayesfactor&amp;quot;),
                   bf_prior = stan_model)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Median&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;MAD&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;CI&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;CI_low&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;CI_high&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BF&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;color - monochromatic, ., .&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.944&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.385&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;90&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.58&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.302&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.031&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;., color - monochromatic, round - square&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.004&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.732&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;90&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.135&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.227&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;These Bayes factors reveal that a model with a main effect for color is &lt;strong&gt;~3&lt;/strong&gt; times more likely than a model without this effect, &lt;strong&gt;and&lt;/strong&gt; that a model &lt;em&gt;without&lt;/em&gt; an interaction is &lt;strong&gt;~1/0.22 = 4.5&lt;/strong&gt; times more likely than a model &lt;em&gt;with&lt;/em&gt; an interaction! But… note that a Bayes factor of 4.5 is considered only &lt;a href=&#34;https://easystats.github.io/report/articles/interpret_metrics.html#bayes-factor-bf&#34;&gt;moderate evidence in favor of the null effect&lt;/a&gt;. As we can see, &lt;strong&gt;a &lt;em&gt;p&lt;/em&gt;-value of 1.0 does not necessarily mean the data strongly supports the null&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Happy Bayesing!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;join-easystats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;join easystats&lt;/h2&gt;
&lt;p&gt;Note that &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;&lt;em&gt;easystats&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt; is a new project in active development, and feedback, suggestions, comments are very welcome! Do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>bayestestR</category>
      
      
            <category>R</category>
      
            <category>bayestestR</category>
      
    </item>
    
    <item>
      <title>Become a Bayesian master with bayestestR (0.2)</title>
      <link>/blog/posts/bayestestr_v2/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_v2/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/bayestestR/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;bayestestr-0.2-is-here&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;bayestestR 0.2 is here!&lt;/h2&gt;
&lt;p&gt;As you might have heard from &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;previous posts&lt;/a&gt;, &lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;we&lt;/a&gt; have recently started to collaborate around the new &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats project&lt;/strong&gt;&lt;/a&gt;, a suite of packages designed to make your life easier. One of the packages, &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;&lt;strong&gt;bayestestR&lt;/strong&gt;&lt;/a&gt;, has just been updated on CRAN.&lt;/p&gt;
&lt;p&gt;And this release is &lt;strong&gt;so packed with new features&lt;/strong&gt; and &lt;strong&gt;improvements&lt;/strong&gt; that it would be impossible to present them all in one post! We have added the computation of different types of &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayes_factors.html&#34;&gt;&lt;strong&gt;Bayes factors (BF)&lt;/strong&gt;&lt;/a&gt;, new &lt;a href=&#34;https://github.com/easystats/see#bayestestr&#34;&gt;&lt;strong&gt;plotting methods&lt;/strong&gt;&lt;/a&gt; (available in the &lt;code&gt;see&lt;/code&gt; package), a new meta-function, &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/describe_posterior.html&#34;&gt;&lt;code&gt;describe_posterior&lt;/code&gt;&lt;/a&gt;, that computes &lt;strong&gt;everything at once&lt;/strong&gt;, and more…&lt;/p&gt;
&lt;p&gt;We also improved the &lt;strong&gt;documentation&lt;/strong&gt;, with new &lt;strong&gt;tutorials&lt;/strong&gt; and &lt;strong&gt;articles&lt;/strong&gt; so that Bayesian analysis can hold no secrets from you. Check them out:&lt;/p&gt;
&lt;div id=&#34;tutorials&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Tutorials&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayestestR.html&#34;&gt;Get Started with Bayesian Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/example1.html&#34;&gt;Example 1: Initiation to Bayesian models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;articles&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Articles&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/credible_interval.html&#34;&gt;Credible Intervals (CIs)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/probability_of_direction.html&#34;&gt;Probability of Direction (pd)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/region_of_practical_equivalence.html&#34;&gt;Region of Practical Equivalence (ROPE)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayes_factors.html&#34;&gt;Bayes Factors (BF)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/indicesEstimationComparison.html&#34;&gt;Comparison of Point-Estimates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/indicesExistenceComparison.html&#34;&gt;Comparison of Indices of Effect Existence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/guidelines.html&#34;&gt;Reporting Guidelines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are also some &lt;a href=&#34;https://easystats.github.io/bayestestR/news/index.html&#34;&gt;&lt;strong&gt;breaking changes&lt;/strong&gt;&lt;/a&gt;, make sure you check them out!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;join-the-team&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Join the team&lt;/h2&gt;
&lt;p&gt;You’ve spotted &lt;strong&gt;an error&lt;/strong&gt;, &lt;strong&gt;a bug&lt;/strong&gt;, &lt;strong&gt;a typo in the documentation&lt;/strong&gt;? Please help us by opening an &lt;a href=&#34;https://github.com/easystats/bayestestR/issues&#34;&gt;issue&lt;/a&gt; or by making a pull request. There is definitely room for improvement. Feel free to let us know how we could further improve this package!&lt;/p&gt;
&lt;p&gt;Also note that &lt;em&gt;easystats&lt;/em&gt; is a new project in active development. So don’t hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt; (you can send one of &lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;us&lt;/a&gt; an email saying, for example, &lt;strong&gt;“leeet me iiiin”&lt;/strong&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>bayestestR</category>
      
      
            <category>R</category>
      
            <category>bayestestR</category>
      
    </item>
    
    <item>
      <title>The &#39;see&#39; package: beautiful figures for easystats</title>
      <link>/blog/posts/see_presentation/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/see_presentation/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/see/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;the-see-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The see package&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;We&lt;/a&gt; have recently decided to collaborate around the new &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats project&lt;/strong&gt;&lt;/a&gt;, a set of packages designed to make your life easier. This project encompasses several packages, devoted for instance to &lt;a href=&#34;https://github.com/easystats/insight&#34;&gt;model access&lt;/a&gt; or &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;Bayesian analysis&lt;/a&gt;, &lt;a href=&#34;https://github.com/easystats/performance&#34;&gt;indices of model performance&lt;/a&gt; or &lt;a href=&#34;https://github.com/easystats/see&#34;&gt;visualisation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Without further ado, please let us introduce the latest addition to the easyverse; the see package!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Essentially, &lt;a href=&#34;https://github.com/easystats/see&#34;&gt;&lt;code&gt;see&lt;/code&gt;&lt;/a&gt; is the visualisation companion to other functions and packages in &lt;strong&gt;easystats&lt;/strong&gt;. See the &lt;strong&gt;list of functions&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/see/reference/index.html&#34;&gt;here&lt;/a&gt;. However, it also includes some nice themes and geoms:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Better looking points&lt;/strong&gt; with &lt;strong&gt;modern theme&lt;/strong&gt; and &lt;strong&gt;flat design colours&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(see)
library(ggplot2)

ggplot(iris, aes(x = Sepal.Width, y = Sepal.Length, color = Species)) +
  geom_point2(size=4, alpha=0.5) +
  scale_color_flat_d() +
  theme_modern()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/see_presentation_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Violin plot&lt;/strong&gt; with &lt;strong&gt;blackboard theme&lt;/strong&gt; and &lt;strong&gt;material design colours&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) + 
  geom_violindot(fill_dots = &amp;quot;white&amp;quot;) + 
  scale_fill_material_d() +
  theme_blackboard()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/see_presentation_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Abyss theme&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bayestestR)
library(rstanarm)

model &amp;lt;- rstanarm::stan_glm(mpg ~ wt + gear + cyl + disp, data = mtcars)

result &amp;lt;- equivalence_test(model, ci = c(.89, .95))

plot(result) +
  theme_abyss() +
  scale_fill_flat()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/see_presentation_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;There is definitely room for improvement, and some new exciting features are already planned. Feel free to let us know how we could further improve this package!&lt;/p&gt;
&lt;p&gt;To conclude, note that &lt;em&gt;easystats&lt;/em&gt; is a new project in active development. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>see</category>
      
      
            <category>R</category>
      
            <category>see</category>
      
    </item>
    
    <item>
      <title>A perfectly normally distributed sample: another post?</title>
      <link>/blog/posts/bayestestr_distribution/</link>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_distribution/</guid>
      <description>


&lt;p&gt;Recently, we published &lt;a href=&#34;https://easystats.github.io/blog/posts/bayestestr_rnorm_perfect/&#34;&gt;a post&lt;/a&gt; presenting a small convenience function, from the &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;bayestestR package&lt;/a&gt;. This function, named &lt;code&gt;rnorm_perfect&lt;/code&gt;, generated an empirical distribution (&lt;em&gt;i.e.&lt;/em&gt;, a vector of values) as close as possible to a desired distribution, in this case the &lt;strong&gt;normal distribution&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;It worked like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Generate a perfect sample
x &amp;lt;- rnorm_perfect(n = 100, mean = 0, sd = 1)

# Visualise it
library(tidyverse)

x %&amp;gt;% 
  density() %&amp;gt;%  # Compute density function
  as.data.frame() %&amp;gt;% 
  ggplot(aes(x=x, y=y)) +
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_distribution_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This function’s name was initially chosen because of its proximity (argument-wise) with its random counterpart &lt;code&gt;rnorm&lt;/code&gt; (it has the same arguments, the same order and the same output type). However, we &lt;a href=&#34;https://github.com/easystats/bayestestR/issues/86&#34;&gt;quickly realised&lt;/a&gt; this this name was not perfect (&lt;em&gt;no pun intended&lt;/em&gt;), as indeed the obtained distribution was not &lt;em&gt;random&lt;/em&gt; (and the &lt;code&gt;r&lt;/code&gt; in &lt;code&gt;rnorm&lt;/code&gt; stands for &lt;em&gt;random&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Thus, after discussion, we decided to change it to &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/distribution.html&#34;&gt;&lt;code&gt;distribution_normal&lt;/code&gt;&lt;/a&gt;. We also used that opportunity to add other types of “perfect” distributions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Generate a perfect sample
x &amp;lt;- distribution_beta(n = 100, 6, 2)

x %&amp;gt;% 
  density() %&amp;gt;% 
  as.data.frame() %&amp;gt;% 
  ggplot(aes(x=x, y=y)) +
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_distribution_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Interestingly, a few days before this update, we received a small email asking:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hi, I saw your blog post and wonder how you define a perfectly normal distribution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We responded:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;that’s actually a good question. I would say an empirical sample having characteristics as close as possible to a canonic Gaussian distribution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After an (ironic?) &lt;em&gt;“Thanks, most helpful!”&lt;/em&gt;, &lt;a href=&#34;https://xianblog.wordpress.com/2019/05/09/a-perfectly-normally-distributed-sample/&#34;&gt;this blog post&lt;/a&gt; got published, which emphasize on the irrelevance of the &lt;code&gt;r&lt;/code&gt; prefix in the function name. Thanks to some of the good points raised in this post, we’ve felt the need to update users on this function.&lt;/p&gt;
&lt;p&gt;Thus, please note that the &lt;code&gt;rnorm_perfect&lt;/code&gt; name will be deprecated in the next version, and ultimately removed to avoid further confusion :)&lt;/p&gt;
&lt;div id=&#34;any-other-suggestions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Any other suggestions?&lt;/h2&gt;
&lt;p&gt;Don’t forget, the &lt;a href=&#34;https://github.com/easystats&#34;&gt;easystats project&lt;/a&gt; (that includes &lt;code&gt;bayestestR&lt;/code&gt;) is very open to contributions! Remember that you can always &lt;a href=&#34;https://github.com/easystats/bayestestR/issues&#34;&gt;make suggestions&lt;/a&gt; and contribute to the package, to actually help improving it, with the spirit of collaboration, and in the tradition of open science ;)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get involved&lt;/h2&gt;
&lt;p&gt;Feel free to let us know how we could further improve this package! Also, note that &lt;a href=&#34;https://github.com/easystats/easystats&#34;&gt;&lt;em&gt;easystats&lt;/em&gt;&lt;/a&gt;, the project supporting &lt;code&gt;bayestestR&lt;/code&gt; is in active development. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>bayestestR</category>
      
            <category>distribution</category>
      
            <category>perfect</category>
      
            <category>gaussian</category>
      
      
            <category>R</category>
      
            <category>bayestestR</category>
      
    </item>
    
    <item>
      <title>Compute R2s and other performance indices for all your models!</title>
      <link>/blog/posts/performance_presentation/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/performance_presentation/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/performance/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Indices of model &lt;strong&gt;performance&lt;/strong&gt; (&lt;em&gt;i.e.&lt;/em&gt;, model quality, goodness of fit, predictive accuracy etc.) are very important, both for model &lt;em&gt;comparison&lt;/em&gt; and model &lt;em&gt;description&lt;/em&gt; purposes. However, their computation or extraction for a wide variety of models can be complex.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;To address this, please let us introduce the &lt;/em&gt;&lt;/strong&gt; &lt;a href=&#34;https://github.com/easystats/performance&#34;&gt;&lt;strong&gt;&lt;code&gt;performance&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;&lt;em&gt;package!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;performance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;performance&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;We&lt;/a&gt; have recently decided to collaborate around the new &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats project&lt;/strong&gt;&lt;/a&gt;, a set of packages designed to make your life &lt;em&gt;easier&lt;/em&gt; (currently WIP). This project encompasses several packages, devoted for instance to &lt;a href=&#34;https://github.com/easystats/insight&#34;&gt;model access&lt;/a&gt; or &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;Bayesian analysis&lt;/a&gt;, as well as &lt;a href=&#34;https://github.com/easystats/performance&#34;&gt;indices of model performance&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The goal of &lt;a href=&#34;https://github.com/easystats/performance&#34;&gt;&lt;code&gt;performance&lt;/code&gt;&lt;/a&gt; is to provide lightweight tools to &lt;strong&gt;assess and check the quality of your model&lt;/strong&gt;. It includes functions such as &lt;a href=&#34;https://easystats.github.io/performance/reference/r2.html&#34;&gt;&lt;code&gt;R2&lt;/code&gt;&lt;/a&gt; for many models (including logistic, mixed and Bayesian models), &lt;a href=&#34;https://easystats.github.io/performance/reference/icc.html&#34;&gt;&lt;code&gt;ICC&lt;/code&gt;&lt;/a&gt; or helpers to check &lt;a href=&#34;https://easystats.github.io/performance/reference/check_convergence.html&#34;&gt;&lt;code&gt;convergence&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://easystats.github.io/performance/reference/check_overdispersion.html&#34;&gt;&lt;code&gt;overdipsersion&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://easystats.github.io/performance/reference/check_zeroinflation.html&#34;&gt;&lt;code&gt;zero-inflation&lt;/code&gt;&lt;/a&gt;. See the &lt;strong&gt;list of functions&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/performance/reference/index.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;performance&lt;/code&gt; can be installed as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;performance&amp;quot;)  # Install the package
library(performance)  # Load it&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;div id=&#34;mixed-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Mixed Models&lt;/h3&gt;
&lt;p&gt;First, we calculate the r-squared value and intra-class correlation coefficient (ICC) for a mixed model, using &lt;a href=&#34;https://easystats.github.io/performance/reference/r2.html&#34;&gt;&lt;strong&gt;r2()&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://easystats.github.io/performance/reference/icc.html&#34;&gt;&lt;strong&gt;icc()&lt;/strong&gt;&lt;/a&gt;. &lt;code&gt;r2()&lt;/code&gt; internally calls the appropriate function for the given model. In case of mixed models this will be &lt;a href=&#34;https://easystats.github.io/performance/reference/r2_nakagawa.html&#34;&gt;&lt;strong&gt;r2_nakagawa()&lt;/strong&gt;&lt;/a&gt;. &lt;code&gt;r2_nakagawa()&lt;/code&gt; computes the marginal and conditional r-squared values, while &lt;code&gt;icc()&lt;/code&gt; calculates an adjusted and conditional ICC, both based on the proposals from &lt;em&gt;Nakagawa et al. 2017&lt;/em&gt;. For more details on the computation of the variances, see &lt;a href=&#34;https://easystats.github.io/insight/reference/get_variance.html&#34;&gt;&lt;strong&gt;get_variance()&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load the lme4 package
library(lme4)

# Fit a mixed model
model &amp;lt;- lmer(Sepal.Width ~ Petal.Length + (1|Species), data = iris)

# compute R2, based on Nakagawa et al. 2017
r2(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; # R2 for Mixed Models
&amp;gt; 
&amp;gt;   Conditional R2: 0.913
&amp;gt;      Marginal R2: 0.216&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# compute intra-class correlation coefficient (ICC)
icc(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; # Intraclass Correlation Coefficient
&amp;gt; 
&amp;gt;      Adjusted ICC: 0.889
&amp;gt;   Conditional ICC: 0.697&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s compute &lt;strong&gt;all available&lt;/strong&gt; indices of performance appropriate for a given model. This can be done via the &lt;a href=&#34;https://easystats.github.io/performance/reference/model_performance.html&#34;&gt;&lt;strong&gt;model_performance()&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compute all performance indices
model_performance(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; # Indices of model performance
&amp;gt; 
&amp;gt;    AIC |    BIC | R2_conditional | R2_marginal |  ICC | RMSE
&amp;gt; ------------------------------------------------------------
&amp;gt; 106.99 | 119.03 |           0.91 |        0.22 | 0.89 | 0.31&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-mixed-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bayesian Mixed Models&lt;/h3&gt;
&lt;p&gt;For Bayesian mixed models, we have the same features available (r-squared, ICC, …). In this example, we focus on the output from &lt;code&gt;model_performance()&lt;/code&gt; only.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load the rstanarm package
library(rstanarm)

# Fit a Bayesian mixed model
model &amp;lt;- stan_glmer(Sepal.Width ~ Petal.Length + (1|Species), data = iris)

# Compute performance indices
model_performance(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; # Indices of model performance
&amp;gt; 
&amp;gt;   ELPD | ELPD_SE | LOOIC | LOOIC_SE |  WAIC |   R2 | R2_marginal | R2_adjusted | RMSE
&amp;gt; -------------------------------------------------------------------------------------
&amp;gt; -43.34 |   10.14 | 86.68 |    20.27 | 86.64 | 0.47 |        0.69 |        0.46 | 0.31&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Don’t forget to check out the&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/performance/&#34;&gt;&lt;strong&gt;documentation here&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;for more!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details about &lt;code&gt;performance&lt;/code&gt;’s features are comming soon, stay tuned ;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;There is definitely room for improvement, and some new exciting features are already planned. Feel free to let us know how we could further improve this package!&lt;/p&gt;
&lt;p&gt;To conclude, note that &lt;em&gt;easystats&lt;/em&gt; is a new project in active development. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>performance</category>
      
            <category>R2</category>
      
            <category>ICC</category>
      
            <category>AIC</category>
      
      
            <category>R</category>
      
            <category>performance</category>
      
    </item>
    
    <item>
      <title>How to easily generate a perfectly normal distribution</title>
      <link>/blog/posts/bayestestr_rnorm_perfect/</link>
      <pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_rnorm_perfect/</guid>
      <description>


&lt;p&gt;Many times, for instance when teaching, I needed to quickly and simply generate a &lt;strong&gt;perfectly normally distributed sample&lt;/strong&gt; to illustrate or show some of its characteristics.&lt;/p&gt;
&lt;p&gt;This is now very easy to do with the new &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;&lt;code&gt;bayestestR&lt;/code&gt;&lt;/a&gt; package, which includes the &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/rnorm_perfect.html&#34;&gt;&lt;code&gt;rnorm_perfect&lt;/code&gt;&lt;/a&gt; function. This function is very similar to the classic &lt;code&gt;rnorm&lt;/code&gt; (same arguments), with the difference that the generated sample is &lt;em&gt;perfectly&lt;/em&gt; normal.&lt;/p&gt;
&lt;div id=&#34;example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;bayestestR&lt;/code&gt; can be installed as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;bayestestR&amp;quot;)  # Install the package
library(bayestestR)  # Load it&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Generate a perfect sample
x &amp;lt;- rnorm_perfect(n = 100, mean = 0, sd = 1)

# Visualise it
library(tidyverse)

x %&amp;gt;% 
  density() %&amp;gt;%  # Compute density function
  as.data.frame() %&amp;gt;% 
  ggplot(aes(x=x, y=y)) +
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_rnorm_perfect_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also easily color some of the parts of the curve, for instance, the observations lying beyond +2 standard deviations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x %&amp;gt;% 
  density() %&amp;gt;%  # Compute density function
  as.data.frame() %&amp;gt;% 
  mutate(outlier = ifelse(x &amp;gt; 2, &amp;quot;Extreme&amp;quot;, &amp;quot;Not extreme&amp;quot;)) %&amp;gt;% 
  ggplot(aes(x=x, y=y, fill=outlier)) +
  geom_ribbon(aes(ymin=0, ymax=y)) +
  theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_rnorm_perfect_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayestestr-and-easystats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;bayestestR and easystats&lt;/h2&gt;
&lt;p&gt;More details about &lt;code&gt;bayestestR&lt;/code&gt;’s features are comming soon, stay tuned ;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Don’t forget to check out the&lt;/strong&gt; &lt;a href=&#34;https://github.com/easystats/bayestestR#documentation&#34;&gt;&lt;strong&gt;documentation here&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;for more!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feel free to let us know how we could further improve this package! Also, note that &lt;a href=&#34;https://github.com/easystats/easystats&#34;&gt;&lt;em&gt;easystats&lt;/em&gt;&lt;/a&gt;, the project supporting &lt;code&gt;bayestestR&lt;/code&gt; is in active development. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>bayestestR</category>
      
            <category>rnorm</category>
      
            <category>normal</category>
      
            <category>gaussian</category>
      
      
            <category>R</category>
      
            <category>bayestestR</category>
      
    </item>
    
    <item>
      <title>Describe and understand Bayesian models and posteriors using bayestestR</title>
      <link>/blog/posts/bayestestr_presentation/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_presentation/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://github.com/easystats/bayestestR/raw/master/man/figures/logo.png&#34; width=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Bayesian framework&lt;/strong&gt; is quickly gaining popularity among scientists, leading to the growing popularity of packages to fit Bayesian models, such as &lt;a href=&#34;https://github.com/stan-dev/rstanarm&#34;&gt;&lt;code&gt;rstanarm&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;code&gt;brms&lt;/code&gt;&lt;/a&gt;. However, extracting summary indices from these models to report them in your manuscript can be quite challenging, especially for new users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;To address this, please let us introduce&lt;/em&gt;&lt;/strong&gt; &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;&lt;strong&gt;&lt;code&gt;bayestestR&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;!&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;bayestestr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;bayestestR&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;We&lt;/a&gt; have recently decided to collaborate around the new &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;project&lt;/strong&gt;, a set of packages designed to make your life &lt;em&gt;easier&lt;/em&gt; (currently very WIP). As we are also Bayesian enthusiasts, we decided to focus on the development of a package devoted to Bayesian post-processing.&lt;/p&gt;
&lt;p&gt;The goal of &lt;a href=&#34;https://github.com/easystats/bayestestR&#34;&gt;&lt;code&gt;bayestestR&lt;/code&gt;&lt;/a&gt; is to provide lightweight tools to help &lt;strong&gt;processing and understanding Bayesian models and posterior distributions&lt;/strong&gt;. It includes several functions used to report and characterise them, such as &lt;a href=&#34;https://github.com/easystats/bayestestR#highest-density-interval-hdi---the-credible-interval-ci&#34;&gt;&lt;strong&gt;Highest Density Interval (&lt;code&gt;hdi&lt;/code&gt;)&lt;/strong&gt;&lt;/a&gt;, the &lt;a href=&#34;https://github.com/easystats/bayestestR#map-estimate&#34;&gt;&lt;strong&gt;highest Maximum A Posteriori (&lt;code&gt;MAP&lt;/code&gt;)&lt;/strong&gt;&lt;/a&gt; or functions to find a suitable &lt;a href=&#34;https://github.com/easystats/bayestestR#find-ropes-appropriate-range&#34;&gt;&lt;strong&gt;ROPE range&lt;/strong&gt;&lt;/a&gt;, compute the &lt;a href=&#34;https://github.com/easystats/bayestestR#rope&#34;&gt;&lt;strong&gt;ROPE percentage&lt;/strong&gt;&lt;/a&gt; or do an &lt;a href=&#34;https://github.com/easystats/bayestestR#equivalence-test&#34;&gt;&lt;strong&gt;Equivalence Test&lt;/strong&gt;&lt;/a&gt;. It also includes more exploratory indices, such as the &lt;a href=&#34;https://github.com/easystats/bayestestR#probability-of-direction-pd&#34;&gt;&lt;strong&gt;Probability of Direction (&lt;code&gt;pd&lt;/code&gt;)&lt;/strong&gt;&lt;/a&gt;, a &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/guidelines.html&#34;&gt;numeric &lt;em&gt;equivalent&lt;/em&gt;&lt;/a&gt; of the frequentist &lt;em&gt;p&lt;/em&gt; value.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bayestestR&lt;/code&gt; can be installed as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;bayestestR&amp;quot;)  # Install the package
library(bayestestR)  # Load it&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;Let’s check whether the effects of my Bayesian regression can be considered as non-negligible. This can be done via the &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/equivalence_test.html#details&#34;&gt;&lt;strong&gt;equivalence test&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load the rstanarm package
library(rstanarm)

# Fit a Bayesian model
model &amp;lt;- stan_glm(mpg ~ wt + cyl + gear + am + hp, data = mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Do the test
equivalence_test(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Test for Practical Equivalence
## 
##   ROPE: [-0.60 0.60]
## 
## Parameter   |        H0 | inside ROPE |       89% HDI
## -----------------------------------------------------
## (Intercept) |  Rejected |      0.00 % | [26.87 46.80]
## wt          |  Rejected |      0.00 % | [-4.29 -1.12]
## cyl         | Undecided |     37.91 % | [-1.88  0.31]
## gear        | Undecided |     41.79 % | [-2.17  1.67]
## am          | Undecided |     19.35 % | [-0.98  4.66]
## hp          |  Accepted |    100.00 % | [-0.05  0.00]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Results can also be plotted, to get a better impression of the posterior distributions and the ROPE-coverage.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Do the test and plot results
plot(equivalence_test(model))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://easystats.github.io/blog/posts/bayestestR_presentation_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Don’t forget to check out the&lt;/strong&gt; &lt;a href=&#34;https://github.com/easystats/bayestestR#documentation&#34;&gt;&lt;strong&gt;documentation here&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;for more!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details about &lt;code&gt;bayestestR&lt;/code&gt;’s features are comming soon, stay tuned ;)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-involved&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;There is definitely room for improvement, and some new exciting features are already planned (BayesFactor objects support, better visualisation methods, etc.). Feel free to let us know how we could further improve this package!&lt;/p&gt;
&lt;p&gt;To conclude, note that &lt;em&gt;easystats&lt;/em&gt; is a new project in active development. Thus, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>bayestestR</category>
      
            <category>posterior</category>
      
            <category>rstanarm</category>
      
            <category>brms</category>
      
      
            <category>R</category>
      
            <category>bayestestR</category>
      
    </item>
    
    <item>
      <title>A unified syntax for accessing models&#39; information</title>
      <link>/blog/posts/insight_presentation/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/insight_presentation/</guid>
      <description>


&lt;p&gt;The richness and variety of packages for building and fitting statistical models in R is absolutely astonishing and contributes to the language’s popularity. However, &lt;strong&gt;this diversity makes it hard for developpers&lt;/strong&gt; that want to create tools that work with different types of models. Indeed, the way to access models’ internal information (such as &lt;strong&gt;parameters names&lt;/strong&gt;, &lt;strong&gt;formulae&lt;/strong&gt;, &lt;strong&gt;data&lt;/strong&gt;, etc.) is &lt;strong&gt;not unified&lt;/strong&gt;, forcing the developers to spend some time figuring out how to do it for each model type.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This time is over!&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;insight&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Insight&lt;/h2&gt;
&lt;p&gt;Recently, &lt;a href=&#34;https://github.com/orgs/easystats/people&#34;&gt;we&lt;/a&gt; have decided to collaborate around the new &lt;a href=&#34;https://github.com/easystats&#34;&gt;easystats&lt;/a&gt; project, a set of packages designed to make your life easier (currently very work in progress). However, in order to create these packages and functions, &lt;strong&gt;we needed a basis&lt;/strong&gt;, a stable cornerstone, that would allow the unified way of accessing models information.&lt;/p&gt;
&lt;p&gt;And &lt;a href=&#34;https://github.com/easystats/insight&#34;&gt;&lt;strong&gt;&lt;code&gt;insight&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; was born.&lt;/p&gt;
&lt;p&gt;The goal of insight is to provide tools to help an &lt;strong&gt;easy, intuitive and consistent accesss&lt;/strong&gt; to information contained in various models. Indeed, although there are generic functions to get information and data from models, many modelling-functions from different packages do not provide such methods to access these information. The insight package aims at closing this gap by providing functions that work for (almost) any model.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;insight&lt;/code&gt; can be installed as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;insight&amp;quot;)  # Install from CRAN
library(insight)  # Load the package&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;Let’s see how it works on a very simple regression model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- lm(Sepal.Length ~ Species, data=iris)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Find the &lt;strong&gt;parameters&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_parameters(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; $conditional
&amp;gt; [1] &amp;quot;(Intercept)&amp;quot;       &amp;quot;Speciesversicolor&amp;quot; &amp;quot;Speciesvirginica&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Find the &lt;strong&gt;outcome’s name&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_response(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; [1] &amp;quot;Sepal.Length&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Find the &lt;strong&gt;formula&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_formula(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; $conditional
&amp;gt; Sepal.Length ~ Species&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Find the &lt;strong&gt;variables in the formula&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_variables(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; $response
&amp;gt; [1] &amp;quot;Sepal.Length&amp;quot;
&amp;gt; 
&amp;gt; $conditional
&amp;gt; [1] &amp;quot;Species&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Find the &lt;strong&gt;algorithm&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_algorithm(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; $algorithm
&amp;gt; [1] &amp;quot;OLS&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Moreover, &lt;code&gt;insight&lt;/code&gt; also includes functions to deal with &lt;strong&gt;Bayesian&lt;/strong&gt; (&lt;code&gt;get_priors()&lt;/code&gt;) and &lt;strong&gt;mixed models&lt;/strong&gt; (&lt;code&gt;find_random()&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;insight&lt;/code&gt; works on a high number of models (see the &lt;a href=&#34;https://github.com/easystats/insight/blob/master/README.md#list-of-supported-packages-and-models&#34;&gt;&lt;strong&gt;list here&lt;/strong&gt;&lt;/a&gt;), and &lt;strong&gt;continue to grow thanks to your suggestions&lt;/strong&gt;! As &lt;em&gt;easystats&lt;/em&gt; is a new project in active development, do not hesitate to contact us if &lt;strong&gt;you want to get involved :)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check out our other blog posts&lt;/strong&gt; &lt;a href=&#34;https://easystats.github.io/blog/posts/&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>insight</category>
      
            <category>access</category>
      
            <category>models</category>
      
            <category>data</category>
      
      
            <category>R</category>
      
            <category>insight</category>
      
    </item>
    
    <item>
      <title>The end of errors in ANOVA reporting</title>
      <link>/blog/posts/report_anova/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/report_anova/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;Psychological science is still massively using analysis of variance (ANOVA)&lt;/strong&gt;. Despite its relative simplicity, I am very often confronted to &lt;strong&gt;errors in its reporting&lt;/strong&gt;, for instance in student’s theses or manuscripts, or even published papers (See the excellent &lt;a href=&#34;http://statcheck.io/&#34;&gt;statcheck&lt;/a&gt; to quickly check the stats of a paper). Beyond the incomplete or just wrong reporting, one can find a tremendous amount of genuine errors (that could influence the results and their interpretation). This error proneness can be at least partly explained by the fact that copy/pasting the (appropriate) values of any statistical software and formatting them textually is a very annoying and tedious process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to end it?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We believe that this could be solved (at least, partially) by the &lt;strong&gt;default implementation of current best practices of statistical reporting&lt;/strong&gt;. A tool that automatically transforms a statistical result into a copy/pastable text. Of course, this automation cannot be suitable for each and every advanced usage, but could be satisfying for a substantial proportion of use cases. &lt;strong&gt;Implementing this unified, end-user oriented pipeline is the goal of the &lt;a href=&#34;https://github.com/easystats/report&#34;&gt;report&lt;/a&gt; package.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;install-report&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Install report&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;report&lt;/code&gt; is part of the new &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;em&gt;easystats&lt;/em&gt;&lt;/a&gt; suite of packages. However, as it is not (yet) on CRAN, you’ll need to install it directly from &lt;a href=&#34;https://github.com/easystats/report&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;easystats/report&amp;quot;)  # Install the latest psycho version

library(report)  # Load the package
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-an-anova&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fit an anova&lt;/h1&gt;
&lt;p&gt;Let’s start by doing a traditional ANOVA with &lt;em&gt;Sepal.Length&lt;/em&gt; (the length of the sepals of some flowers) as dependent variable, and the &lt;em&gt;Species&lt;/em&gt; as categorical predictor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aov_results &amp;lt;- aov(Sepal.Length ~ Species, data=iris)  # Fit the ANOVA&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;formatted-output&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Formatted output&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;report&lt;/code&gt; package include a single function, namely &lt;code&gt;report()&lt;/code&gt;, that can be applied to an ANOVA object to format its content.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;report(aov_results)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It formats the results, computes the partial omega-squared as an index of effect size (better than the eta2, see &lt;a href=&#34;https://academic.oup.com/hcr/article-abstract/28/4/612/4331349&#34;&gt;Levine et al. 2002&lt;/a&gt;, &lt;a href=&#34;http://journals.sagepub.com/doi/abs/10.1177/0013164404264848&#34;&gt;Pierce et al. 2004&lt;/a&gt;) as well as its &lt;a href=&#34;http://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize&#34;&gt;interpretation&lt;/a&gt; and presents the results in an APA-compatible way.&lt;/p&gt;
&lt;p&gt;Note that a table-output is also available:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aov_results %&amp;gt;% 
  report() %&amp;gt;% 
  to_table()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;evolution&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Evolution&lt;/h1&gt;
&lt;p&gt;Of course, these reporting standards should change, depending on new expert recommendations or official guidelines. &lt;strong&gt;The goal of this package is to flexibly adaptive to new changes and good practices evolution&lt;/strong&gt;. Therefore, if you have any advices, opinions or such, we encourage you to either let us know by opening an &lt;a href=&#34;https://github.com/easystats/report/issues&#34;&gt;issue&lt;/a&gt;, or even better, try to implement them yourself by &lt;a href=&#34;https://github.com/easystats/report/blob/master/.github/CONTRIBUTING.md&#34;&gt;contributing&lt;/a&gt; to the code.&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>report</category>
      
            <category>ANOVA</category>
      
            <category>APA</category>
      
            <category>results</category>
      
      
            <category>R</category>
      
            <category>report</category>
      
    </item>
    
    <item>
      <title>Formatted correlation output with effect sizes</title>
      <link>/blog/posts/report_correlation/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/report_correlation/</guid>
      <description>


&lt;p&gt;One of the most time-consuming part of data analysis in science is the copy-pasting of specific values of some R output to a manuscript or a report. This task is frustrating, prone to errors, and increases the variability of statistical reporting. At the sime time, standardizing practices of what and how to report is crucial for reproducibility and clarity. &lt;strong&gt;The new &lt;a href=&#34;https://github.com/easystats/report&#34;&gt;report&lt;/a&gt; package was designed specifically to do this job&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;install-report&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Install report&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;report&lt;/code&gt; is part of the new &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;em&gt;easystats&lt;/em&gt;&lt;/a&gt; suite of packages. However, as it is not (yet) on CRAN, you’ll need to install it directly from &lt;a href=&#34;https://github.com/easystats/report&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;easystats/report&amp;quot;)  # Install the latest psycho version

library(report)  # Load the package
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;do-a-correlation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Do a correlation&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- iris  # Load the traditional iris dataset into an object called df (for dataframe)
cor_results &amp;lt;- cor.test(df$Sepal.Length, df$Petal.Length)  # Compute a correlation and store its result&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;formatted-output&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Formatted output&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;report&lt;/code&gt; package include a single function, namely &lt;code&gt;report()&lt;/code&gt;, that can be applied to a correlation to format its content.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;report(cor_results)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The formatted output includes the &lt;strong&gt;direction&lt;/strong&gt;, &lt;strong&gt;effect size&lt;/strong&gt; (interpreted by default using &lt;strong&gt;&lt;a href=&#34;https://easystats.github.io/report/articles/interpret_metrics.html#correlation-r&#34;&gt;Cohen’s (1988)&lt;/a&gt;&lt;/strong&gt; rules of thumb) and &lt;strong&gt;confidence intervals&lt;/strong&gt;. Now, you can just copy and paste this line into your report and focus on more important things.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evolution&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Evolution&lt;/h1&gt;
&lt;p&gt;Of course, these reporting standards should change, depending on new expert recommendations or official guidelines. &lt;strong&gt;The goal of this package is to flexibly adaptive to new changes and good practices evolution&lt;/strong&gt;. Therefore, if you have any advices, opinions or such, we encourage you to either let us know by opening an &lt;a href=&#34;https://github.com/easystats/report/issues&#34;&gt;issue&lt;/a&gt;, or even better, try to implement them yourself by &lt;a href=&#34;https://github.com/easystats/report/blob/master/.github/CONTRIBUTING.md&#34;&gt;contributing&lt;/a&gt; to the code.&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>easystats</category>
      
            <category>report</category>
      
            <category>correlations</category>
      
            <category>APA</category>
      
            <category>results</category>
      
      
            <category>R</category>
      
            <category>report</category>
      
    </item>
    
  </channel>
</rss>