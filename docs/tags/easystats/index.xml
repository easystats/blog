<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Easystats on easystats</title>
    <link>/blog/tags/easystats/</link>
    <description>Recent content in Easystats on easystats</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 15 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/blog/tags/easystats/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Describe and understand Bayesian models and posteriors using bayestestR</title>
      <link>/blog/posts/bayestestr_presentation/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/bayestestr_presentation/</guid>
      <description>The Bayesian framework is quickly gaining popularity among scientists, leading to the growing popularity of packages to fit Bayesian models, such as rstanarm or brms. However, extracting summary indices from these models to report them in your manuscript can be quite challenging, especially for new users.
To address this, please let us introduce bayestestR!
bayestestRWe have recently decided to collaborate around the new easystats project, a set of packages designed to make your life easier (currently very WIP).</description>
    </item>
    
    <item>
      <title>A unified syntax for accessing models&#39; information</title>
      <link>/blog/posts/insight_presentation/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/insight_presentation/</guid>
      <description>The richness and variety of packages for building and fitting statistical models in R is absolutely astonishing and contributes to the language’s popularity. However, this diversity makes it hard for developpers that want to create tools that work with different types of models. Indeed, the way to access models’ internal information (such as parameters names, formulae, data, etc.) is not unified, forcing the developers to spend some time figuring out how to do it for each model type.</description>
    </item>
    
    <item>
      <title>The end of errors in ANOVA reporting</title>
      <link>/blog/posts/report_anova/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/report_anova/</guid>
      <description>Psychological science is still massively using analysis of variance (ANOVA). Despite its relative simplicity, I am very often confronted to errors in its reporting, for instance in student’s theses or manuscripts, or even published papers (See the excellent statcheck to quickly check the stats of a paper). Beyond the incomplete or just wrong reporting, one can find a tremendous amount of genuine errors (that could influence the results and their interpretation).</description>
    </item>
    
    <item>
      <title>Formatted correlation output with effect sizes</title>
      <link>/blog/posts/report_correlation/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/report_correlation/</guid>
      <description>One of the most time-consuming part of data analysis in science is the copy-pasting of specific values of some R output to a manuscript or a report. This task is frustrating, prone to errors, and increases the variability of statistical reporting. At the sime time, standardizing practices of what and how to report is crucial for reproducibility and clarity. The new report package was designed specifically to do this job.</description>
    </item>
    
  </channel>
</rss>